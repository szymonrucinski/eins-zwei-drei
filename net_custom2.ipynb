{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import plot_confusion_matrix\n",
    "from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms.functional as TF\n",
    "from utils import pytorchtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 1000\n",
    "patience = 10\n",
    "batch_size = 512\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='..//set', \n",
    "                                           train=True, \n",
    "                                           transform=transform,  \n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='..///set', \n",
    "                                          train=False, \n",
    "                                          transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        #layers\n",
    "        self.l1 = nn.Linear(784, 100) # layer 1\n",
    "        self.l2 = nn.Linear(100, 50) # layer 2\n",
    "        self.l3 = nn.Linear(50, 10) # layer 3\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]          78,500\n",
      "              ReLU-2               [-1, 1, 100]               0\n",
      "            Linear-3                [-1, 1, 50]           5,050\n",
      "              ReLU-4                [-1, 1, 50]               0\n",
      "            Linear-5                [-1, 1, 10]             510\n",
      "================================================================\n",
      "Total params: 84,060\n",
      "Trainable params: 84,060\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 0.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to track the training loss as the model trains\n",
    "train_losses = []\n",
    "# to track the validation loss as the model trains\n",
    "valid_losses = []\n",
    "# to track the average training loss per epoch as the model trains\n",
    "avg_train_losses = []\n",
    "# to track the average validation loss per epoch as the model trains\n",
    "avg_valid_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "train_loss: 2.29867 valid_loss: 2.28789\n",
      "Validation loss decreased (inf --> 2.287889).  Saving model ...\n",
      "0\n",
      "train_loss: 2.27870 valid_loss: 2.26880\n",
      "Validation loss decreased (2.287889 --> 2.268797).  Saving model ...\n",
      "1\n",
      "train_loss: 2.26036 valid_loss: 2.24943\n",
      "Validation loss decreased (2.268797 --> 2.249432).  Saving model ...\n",
      "2\n",
      "train_loss: 2.24067 valid_loss: 2.22818\n",
      "Validation loss decreased (2.249432 --> 2.228184).  Saving model ...\n",
      "3\n",
      "train_loss: 2.21908 valid_loss: 2.20510\n",
      "Validation loss decreased (2.228184 --> 2.205098).  Saving model ...\n",
      "4\n",
      "train_loss: 2.19562 valid_loss: 2.17991\n",
      "Validation loss decreased (2.205098 --> 2.179907).  Saving model ...\n",
      "5\n",
      "train_loss: 2.16986 valid_loss: 2.15261\n",
      "Validation loss decreased (2.179907 --> 2.152606).  Saving model ...\n",
      "6\n",
      "train_loss: 2.14198 valid_loss: 2.12260\n",
      "Validation loss decreased (2.152606 --> 2.122602).  Saving model ...\n",
      "7\n",
      "train_loss: 2.11061 valid_loss: 2.08867\n",
      "Validation loss decreased (2.122602 --> 2.088671).  Saving model ...\n",
      "8\n",
      "train_loss: 2.07536 valid_loss: 2.05069\n",
      "Validation loss decreased (2.088671 --> 2.050691).  Saving model ...\n",
      "9\n",
      "train_loss: 2.03602 valid_loss: 2.00901\n",
      "Validation loss decreased (2.050691 --> 2.009011).  Saving model ...\n",
      "10\n",
      "train_loss: 1.99304 valid_loss: 1.96349\n",
      "Validation loss decreased (2.009011 --> 1.963488).  Saving model ...\n",
      "11\n",
      "train_loss: 1.94624 valid_loss: 1.91397\n",
      "Validation loss decreased (1.963488 --> 1.913974).  Saving model ...\n",
      "12\n",
      "train_loss: 1.89636 valid_loss: 1.86071\n",
      "Validation loss decreased (1.913974 --> 1.860706).  Saving model ...\n",
      "13\n",
      "train_loss: 1.84202 valid_loss: 1.80383\n",
      "Validation loss decreased (1.860706 --> 1.803827).  Saving model ...\n",
      "14\n",
      "train_loss: 1.78402 valid_loss: 1.74393\n",
      "Validation loss decreased (1.803827 --> 1.743935).  Saving model ...\n",
      "15\n",
      "train_loss: 1.72434 valid_loss: 1.68194\n",
      "Validation loss decreased (1.743935 --> 1.681940).  Saving model ...\n",
      "16\n",
      "train_loss: 1.66216 valid_loss: 1.61834\n",
      "Validation loss decreased (1.681940 --> 1.618336).  Saving model ...\n",
      "17\n",
      "train_loss: 1.59890 valid_loss: 1.55393\n",
      "Validation loss decreased (1.618336 --> 1.553925).  Saving model ...\n",
      "18\n",
      "train_loss: 1.53537 valid_loss: 1.48926\n",
      "Validation loss decreased (1.553925 --> 1.489256).  Saving model ...\n",
      "19\n",
      "train_loss: 1.47163 valid_loss: 1.42510\n",
      "Validation loss decreased (1.489256 --> 1.425098).  Saving model ...\n",
      "20\n",
      "train_loss: 1.40845 valid_loss: 1.36216\n",
      "Validation loss decreased (1.425098 --> 1.362157).  Saving model ...\n",
      "21\n",
      "train_loss: 1.34733 valid_loss: 1.30106\n",
      "Validation loss decreased (1.362157 --> 1.301059).  Saving model ...\n",
      "22\n",
      "train_loss: 1.28654 valid_loss: 1.24190\n",
      "Validation loss decreased (1.301059 --> 1.241896).  Saving model ...\n",
      "23\n",
      "train_loss: 1.23053 valid_loss: 1.18566\n",
      "Validation loss decreased (1.241896 --> 1.185656).  Saving model ...\n",
      "24\n",
      "train_loss: 1.17683 valid_loss: 1.13257\n",
      "Validation loss decreased (1.185656 --> 1.132572).  Saving model ...\n",
      "25\n",
      "train_loss: 1.12518 valid_loss: 1.08266\n",
      "Validation loss decreased (1.132572 --> 1.082663).  Saving model ...\n",
      "26\n",
      "train_loss: 1.07695 valid_loss: 1.03626\n",
      "Validation loss decreased (1.082663 --> 1.036256).  Saving model ...\n",
      "27\n",
      "train_loss: 1.03254 valid_loss: 0.99296\n",
      "Validation loss decreased (1.036256 --> 0.992956).  Saving model ...\n",
      "28\n",
      "train_loss: 0.99071 valid_loss: 0.95288\n",
      "Validation loss decreased (0.992956 --> 0.952878).  Saving model ...\n",
      "29\n",
      "train_loss: 0.95243 valid_loss: 0.91596\n",
      "Validation loss decreased (0.952878 --> 0.915956).  Saving model ...\n",
      "30\n",
      "train_loss: 0.91656 valid_loss: 0.88201\n",
      "Validation loss decreased (0.915956 --> 0.882008).  Saving model ...\n",
      "31\n",
      "train_loss: 0.88465 valid_loss: 0.85061\n",
      "Validation loss decreased (0.882008 --> 0.850611).  Saving model ...\n",
      "32\n",
      "train_loss: 0.85387 valid_loss: 0.82206\n",
      "Validation loss decreased (0.850611 --> 0.822060).  Saving model ...\n",
      "33\n",
      "train_loss: 0.82650 valid_loss: 0.79566\n",
      "Validation loss decreased (0.822060 --> 0.795658).  Saving model ...\n",
      "34\n",
      "train_loss: 0.80164 valid_loss: 0.77157\n",
      "Validation loss decreased (0.795658 --> 0.771570).  Saving model ...\n",
      "35\n",
      "train_loss: 0.77831 valid_loss: 0.74953\n",
      "Validation loss decreased (0.771570 --> 0.749528).  Saving model ...\n",
      "36\n",
      "train_loss: 0.75661 valid_loss: 0.72872\n",
      "Validation loss decreased (0.749528 --> 0.728717).  Saving model ...\n",
      "37\n",
      "train_loss: 0.73631 valid_loss: 0.70976\n",
      "Validation loss decreased (0.728717 --> 0.709756).  Saving model ...\n",
      "38\n",
      "train_loss: 0.71824 valid_loss: 0.69227\n",
      "Validation loss decreased (0.709756 --> 0.692268).  Saving model ...\n",
      "39\n",
      "train_loss: 0.70150 valid_loss: 0.67588\n",
      "Validation loss decreased (0.692268 --> 0.675878).  Saving model ...\n",
      "40\n",
      "train_loss: 0.68479 valid_loss: 0.66105\n",
      "Validation loss decreased (0.675878 --> 0.661052).  Saving model ...\n",
      "41\n",
      "train_loss: 0.67098 valid_loss: 0.64708\n",
      "Validation loss decreased (0.661052 --> 0.647085).  Saving model ...\n",
      "42\n",
      "train_loss: 0.65818 valid_loss: 0.63391\n",
      "Validation loss decreased (0.647085 --> 0.633913).  Saving model ...\n",
      "43\n",
      "train_loss: 0.64382 valid_loss: 0.62161\n",
      "Validation loss decreased (0.633913 --> 0.621612).  Saving model ...\n",
      "44\n",
      "train_loss: 0.63267 valid_loss: 0.61058\n",
      "Validation loss decreased (0.621612 --> 0.610578).  Saving model ...\n",
      "45\n",
      "train_loss: 0.62063 valid_loss: 0.59980\n",
      "Validation loss decreased (0.610578 --> 0.599802).  Saving model ...\n",
      "46\n",
      "train_loss: 0.61079 valid_loss: 0.58943\n",
      "Validation loss decreased (0.599802 --> 0.589432).  Saving model ...\n",
      "47\n",
      "train_loss: 0.60105 valid_loss: 0.57983\n",
      "Validation loss decreased (0.589432 --> 0.579827).  Saving model ...\n",
      "48\n",
      "train_loss: 0.59042 valid_loss: 0.57090\n",
      "Validation loss decreased (0.579827 --> 0.570895).  Saving model ...\n",
      "49\n",
      "train_loss: 0.58238 valid_loss: 0.56263\n",
      "Validation loss decreased (0.570895 --> 0.562635).  Saving model ...\n",
      "50\n",
      "train_loss: 0.57356 valid_loss: 0.55435\n",
      "Validation loss decreased (0.562635 --> 0.554354).  Saving model ...\n",
      "51\n",
      "train_loss: 0.56653 valid_loss: 0.54677\n",
      "Validation loss decreased (0.554354 --> 0.546772).  Saving model ...\n",
      "52\n",
      "train_loss: 0.55932 valid_loss: 0.53933\n",
      "Validation loss decreased (0.546772 --> 0.539328).  Saving model ...\n",
      "53\n",
      "train_loss: 0.55271 valid_loss: 0.53259\n",
      "Validation loss decreased (0.539328 --> 0.532592).  Saving model ...\n",
      "54\n",
      "train_loss: 0.54508 valid_loss: 0.52609\n",
      "Validation loss decreased (0.532592 --> 0.526094).  Saving model ...\n",
      "55\n",
      "train_loss: 0.53899 valid_loss: 0.51977\n",
      "Validation loss decreased (0.526094 --> 0.519768).  Saving model ...\n",
      "56\n",
      "train_loss: 0.53309 valid_loss: 0.51373\n",
      "Validation loss decreased (0.519768 --> 0.513734).  Saving model ...\n",
      "57\n",
      "train_loss: 0.52592 valid_loss: 0.50781\n",
      "Validation loss decreased (0.513734 --> 0.507806).  Saving model ...\n",
      "58\n",
      "train_loss: 0.52019 valid_loss: 0.50267\n",
      "Validation loss decreased (0.507806 --> 0.502667).  Saving model ...\n",
      "59\n",
      "train_loss: 0.51488 valid_loss: 0.49697\n",
      "Validation loss decreased (0.502667 --> 0.496965).  Saving model ...\n",
      "60\n",
      "train_loss: 0.50943 valid_loss: 0.49198\n",
      "Validation loss decreased (0.496965 --> 0.491981).  Saving model ...\n",
      "61\n",
      "train_loss: 0.50427 valid_loss: 0.48755\n",
      "Validation loss decreased (0.491981 --> 0.487553).  Saving model ...\n",
      "62\n",
      "train_loss: 0.49994 valid_loss: 0.48251\n",
      "Validation loss decreased (0.487553 --> 0.482513).  Saving model ...\n",
      "63\n",
      "train_loss: 0.49553 valid_loss: 0.47814\n",
      "Validation loss decreased (0.482513 --> 0.478139).  Saving model ...\n",
      "64\n",
      "train_loss: 0.49053 valid_loss: 0.47389\n",
      "Validation loss decreased (0.478139 --> 0.473894).  Saving model ...\n",
      "65\n",
      "train_loss: 0.48573 valid_loss: 0.46986\n",
      "Validation loss decreased (0.473894 --> 0.469862).  Saving model ...\n",
      "66\n",
      "train_loss: 0.48176 valid_loss: 0.46562\n",
      "Validation loss decreased (0.469862 --> 0.465616).  Saving model ...\n",
      "67\n",
      "train_loss: 0.47804 valid_loss: 0.46170\n",
      "Validation loss decreased (0.465616 --> 0.461698).  Saving model ...\n",
      "68\n",
      "train_loss: 0.47450 valid_loss: 0.45797\n",
      "Validation loss decreased (0.461698 --> 0.457965).  Saving model ...\n",
      "69\n",
      "train_loss: 0.47124 valid_loss: 0.45449\n",
      "Validation loss decreased (0.457965 --> 0.454491).  Saving model ...\n",
      "70\n",
      "train_loss: 0.46791 valid_loss: 0.45118\n",
      "Validation loss decreased (0.454491 --> 0.451181).  Saving model ...\n",
      "71\n",
      "train_loss: 0.46375 valid_loss: 0.44754\n",
      "Validation loss decreased (0.451181 --> 0.447540).  Saving model ...\n",
      "72\n",
      "train_loss: 0.46074 valid_loss: 0.44429\n",
      "Validation loss decreased (0.447540 --> 0.444285).  Saving model ...\n",
      "73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.45610 valid_loss: 0.44087\n",
      "Validation loss decreased (0.444285 --> 0.440869).  Saving model ...\n",
      "74\n",
      "train_loss: 0.45365 valid_loss: 0.43804\n",
      "Validation loss decreased (0.440869 --> 0.438041).  Saving model ...\n",
      "75\n",
      "train_loss: 0.45179 valid_loss: 0.43515\n",
      "Validation loss decreased (0.438041 --> 0.435146).  Saving model ...\n",
      "76\n",
      "train_loss: 0.44758 valid_loss: 0.43225\n",
      "Validation loss decreased (0.435146 --> 0.432246).  Saving model ...\n",
      "77\n",
      "train_loss: 0.44465 valid_loss: 0.42960\n",
      "Validation loss decreased (0.432246 --> 0.429596).  Saving model ...\n",
      "78\n",
      "train_loss: 0.44130 valid_loss: 0.42644\n",
      "Validation loss decreased (0.429596 --> 0.426442).  Saving model ...\n",
      "79\n",
      "train_loss: 0.43927 valid_loss: 0.42377\n",
      "Validation loss decreased (0.426442 --> 0.423767).  Saving model ...\n",
      "80\n",
      "train_loss: 0.43710 valid_loss: 0.42140\n",
      "Validation loss decreased (0.423767 --> 0.421396).  Saving model ...\n",
      "81\n",
      "train_loss: 0.43309 valid_loss: 0.41884\n",
      "Validation loss decreased (0.421396 --> 0.418841).  Saving model ...\n",
      "82\n",
      "train_loss: 0.43052 valid_loss: 0.41636\n",
      "Validation loss decreased (0.418841 --> 0.416357).  Saving model ...\n",
      "83\n",
      "train_loss: 0.42853 valid_loss: 0.41438\n",
      "Validation loss decreased (0.416357 --> 0.414384).  Saving model ...\n",
      "84\n",
      "train_loss: 0.42570 valid_loss: 0.41184\n",
      "Validation loss decreased (0.414384 --> 0.411840).  Saving model ...\n",
      "85\n",
      "train_loss: 0.42399 valid_loss: 0.40985\n",
      "Validation loss decreased (0.411840 --> 0.409850).  Saving model ...\n",
      "86\n",
      "train_loss: 0.42151 valid_loss: 0.40740\n",
      "Validation loss decreased (0.409850 --> 0.407405).  Saving model ...\n",
      "87\n",
      "train_loss: 0.41931 valid_loss: 0.40553\n",
      "Validation loss decreased (0.407405 --> 0.405532).  Saving model ...\n",
      "88\n",
      "train_loss: 0.41740 valid_loss: 0.40329\n",
      "Validation loss decreased (0.405532 --> 0.403286).  Saving model ...\n",
      "89\n",
      "train_loss: 0.41550 valid_loss: 0.40185\n",
      "Validation loss decreased (0.403286 --> 0.401853).  Saving model ...\n",
      "90\n",
      "train_loss: 0.41415 valid_loss: 0.39927\n",
      "Validation loss decreased (0.401853 --> 0.399269).  Saving model ...\n",
      "91\n",
      "train_loss: 0.41109 valid_loss: 0.39747\n",
      "Validation loss decreased (0.399269 --> 0.397470).  Saving model ...\n",
      "92\n",
      "train_loss: 0.40830 valid_loss: 0.39579\n",
      "Validation loss decreased (0.397470 --> 0.395789).  Saving model ...\n",
      "93\n",
      "train_loss: 0.40687 valid_loss: 0.39384\n",
      "Validation loss decreased (0.395789 --> 0.393836).  Saving model ...\n",
      "94\n",
      "train_loss: 0.40486 valid_loss: 0.39205\n",
      "Validation loss decreased (0.393836 --> 0.392053).  Saving model ...\n",
      "95\n",
      "train_loss: 0.40367 valid_loss: 0.39042\n",
      "Validation loss decreased (0.392053 --> 0.390419).  Saving model ...\n",
      "96\n",
      "train_loss: 0.40199 valid_loss: 0.38883\n",
      "Validation loss decreased (0.390419 --> 0.388830).  Saving model ...\n",
      "97\n",
      "train_loss: 0.40016 valid_loss: 0.38707\n",
      "Validation loss decreased (0.388830 --> 0.387071).  Saving model ...\n",
      "98\n",
      "train_loss: 0.39889 valid_loss: 0.38566\n",
      "Validation loss decreased (0.387071 --> 0.385658).  Saving model ...\n",
      "99\n",
      "train_loss: 0.39674 valid_loss: 0.38379\n",
      "Validation loss decreased (0.385658 --> 0.383786).  Saving model ...\n",
      "100\n",
      "train_loss: 0.39519 valid_loss: 0.38231\n",
      "Validation loss decreased (0.383786 --> 0.382307).  Saving model ...\n",
      "101\n",
      "train_loss: 0.39353 valid_loss: 0.38095\n",
      "Validation loss decreased (0.382307 --> 0.380954).  Saving model ...\n",
      "102\n",
      "train_loss: 0.39301 valid_loss: 0.37953\n",
      "Validation loss decreased (0.380954 --> 0.379527).  Saving model ...\n",
      "103\n",
      "train_loss: 0.39101 valid_loss: 0.37802\n",
      "Validation loss decreased (0.379527 --> 0.378024).  Saving model ...\n",
      "104\n",
      "train_loss: 0.38886 valid_loss: 0.37655\n",
      "Validation loss decreased (0.378024 --> 0.376550).  Saving model ...\n",
      "105\n",
      "train_loss: 0.38800 valid_loss: 0.37498\n",
      "Validation loss decreased (0.376550 --> 0.374980).  Saving model ...\n",
      "106\n",
      "train_loss: 0.38580 valid_loss: 0.37419\n",
      "Validation loss decreased (0.374980 --> 0.374185).  Saving model ...\n",
      "107\n",
      "train_loss: 0.38475 valid_loss: 0.37235\n",
      "Validation loss decreased (0.374185 --> 0.372352).  Saving model ...\n",
      "108\n",
      "train_loss: 0.38301 valid_loss: 0.37116\n",
      "Validation loss decreased (0.372352 --> 0.371155).  Saving model ...\n",
      "109\n",
      "train_loss: 0.38232 valid_loss: 0.37001\n",
      "Validation loss decreased (0.371155 --> 0.370011).  Saving model ...\n",
      "110\n",
      "train_loss: 0.38026 valid_loss: 0.36888\n",
      "Validation loss decreased (0.370011 --> 0.368877).  Saving model ...\n",
      "111\n",
      "train_loss: 0.37956 valid_loss: 0.36773\n",
      "Validation loss decreased (0.368877 --> 0.367729).  Saving model ...\n",
      "112\n",
      "train_loss: 0.37836 valid_loss: 0.36618\n",
      "Validation loss decreased (0.367729 --> 0.366183).  Saving model ...\n",
      "113\n",
      "train_loss: 0.37736 valid_loss: 0.36527\n",
      "Validation loss decreased (0.366183 --> 0.365270).  Saving model ...\n",
      "114\n",
      "train_loss: 0.37517 valid_loss: 0.36382\n",
      "Validation loss decreased (0.365270 --> 0.363821).  Saving model ...\n",
      "115\n",
      "train_loss: 0.37568 valid_loss: 0.36289\n",
      "Validation loss decreased (0.363821 --> 0.362895).  Saving model ...\n",
      "116\n",
      "train_loss: 0.37430 valid_loss: 0.36186\n",
      "Validation loss decreased (0.362895 --> 0.361859).  Saving model ...\n",
      "117\n",
      "train_loss: 0.37224 valid_loss: 0.36096\n",
      "Validation loss decreased (0.361859 --> 0.360956).  Saving model ...\n",
      "118\n",
      "train_loss: 0.37184 valid_loss: 0.35966\n",
      "Validation loss decreased (0.360956 --> 0.359657).  Saving model ...\n",
      "119\n",
      "train_loss: 0.36910 valid_loss: 0.35849\n",
      "Validation loss decreased (0.359657 --> 0.358489).  Saving model ...\n",
      "120\n",
      "train_loss: 0.36895 valid_loss: 0.35740\n",
      "Validation loss decreased (0.358489 --> 0.357396).  Saving model ...\n",
      "121\n",
      "train_loss: 0.36743 valid_loss: 0.35641\n",
      "Validation loss decreased (0.357396 --> 0.356405).  Saving model ...\n",
      "122\n",
      "train_loss: 0.36651 valid_loss: 0.35565\n",
      "Validation loss decreased (0.356405 --> 0.355650).  Saving model ...\n",
      "123\n",
      "train_loss: 0.36551 valid_loss: 0.35456\n",
      "Validation loss decreased (0.355650 --> 0.354564).  Saving model ...\n",
      "124\n",
      "train_loss: 0.36495 valid_loss: 0.35371\n",
      "Validation loss decreased (0.354564 --> 0.353706).  Saving model ...\n",
      "125\n",
      "train_loss: 0.36319 valid_loss: 0.35239\n",
      "Validation loss decreased (0.353706 --> 0.352391).  Saving model ...\n",
      "126\n",
      "train_loss: 0.36275 valid_loss: 0.35186\n",
      "Validation loss decreased (0.352391 --> 0.351860).  Saving model ...\n",
      "127\n",
      "train_loss: 0.36169 valid_loss: 0.35067\n",
      "Validation loss decreased (0.351860 --> 0.350666).  Saving model ...\n",
      "128\n",
      "train_loss: 0.36134 valid_loss: 0.34998\n",
      "Validation loss decreased (0.350666 --> 0.349979).  Saving model ...\n",
      "129\n",
      "train_loss: 0.35939 valid_loss: 0.34893\n",
      "Validation loss decreased (0.349979 --> 0.348932).  Saving model ...\n",
      "130\n",
      "train_loss: 0.35863 valid_loss: 0.34800\n",
      "Validation loss decreased (0.348932 --> 0.347997).  Saving model ...\n",
      "131\n",
      "train_loss: 0.35742 valid_loss: 0.34705\n",
      "Validation loss decreased (0.347997 --> 0.347053).  Saving model ...\n",
      "132\n",
      "train_loss: 0.35652 valid_loss: 0.34605\n",
      "Validation loss decreased (0.347053 --> 0.346046).  Saving model ...\n",
      "133\n",
      "train_loss: 0.35513 valid_loss: 0.34558\n",
      "Validation loss decreased (0.346046 --> 0.345582).  Saving model ...\n",
      "134\n",
      "train_loss: 0.35440 valid_loss: 0.34442\n",
      "Validation loss decreased (0.345582 --> 0.344423).  Saving model ...\n",
      "135\n",
      "train_loss: 0.35377 valid_loss: 0.34404\n",
      "Validation loss decreased (0.344423 --> 0.344041).  Saving model ...\n",
      "136\n",
      "train_loss: 0.35383 valid_loss: 0.34311\n",
      "Validation loss decreased (0.344041 --> 0.343113).  Saving model ...\n",
      "137\n",
      "train_loss: 0.35255 valid_loss: 0.34224\n",
      "Validation loss decreased (0.343113 --> 0.342239).  Saving model ...\n",
      "138\n",
      "train_loss: 0.35228 valid_loss: 0.34130\n",
      "Validation loss decreased (0.342239 --> 0.341303).  Saving model ...\n",
      "139\n",
      "train_loss: 0.35108 valid_loss: 0.34068\n",
      "Validation loss decreased (0.341303 --> 0.340681).  Saving model ...\n",
      "140\n",
      "train_loss: 0.34924 valid_loss: 0.33991\n",
      "Validation loss decreased (0.340681 --> 0.339909).  Saving model ...\n",
      "141\n",
      "train_loss: 0.34916 valid_loss: 0.33896\n",
      "Validation loss decreased (0.339909 --> 0.338959).  Saving model ...\n",
      "142\n",
      "train_loss: 0.34769 valid_loss: 0.33815\n",
      "Validation loss decreased (0.338959 --> 0.338152).  Saving model ...\n",
      "143\n",
      "train_loss: 0.34707 valid_loss: 0.33769\n",
      "Validation loss decreased (0.338152 --> 0.337692).  Saving model ...\n",
      "144\n",
      "train_loss: 0.34605 valid_loss: 0.33698\n",
      "Validation loss decreased (0.337692 --> 0.336976).  Saving model ...\n",
      "145\n",
      "train_loss: 0.34619 valid_loss: 0.33624\n",
      "Validation loss decreased (0.336976 --> 0.336238).  Saving model ...\n",
      "146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.34544 valid_loss: 0.33544\n",
      "Validation loss decreased (0.336238 --> 0.335443).  Saving model ...\n",
      "147\n",
      "train_loss: 0.34412 valid_loss: 0.33460\n",
      "Validation loss decreased (0.335443 --> 0.334604).  Saving model ...\n",
      "148\n",
      "train_loss: 0.34288 valid_loss: 0.33385\n",
      "Validation loss decreased (0.334604 --> 0.333854).  Saving model ...\n",
      "149\n",
      "train_loss: 0.34273 valid_loss: 0.33346\n",
      "Validation loss decreased (0.333854 --> 0.333465).  Saving model ...\n",
      "150\n",
      "train_loss: 0.34219 valid_loss: 0.33260\n",
      "Validation loss decreased (0.333465 --> 0.332599).  Saving model ...\n",
      "151\n",
      "train_loss: 0.34099 valid_loss: 0.33206\n",
      "Validation loss decreased (0.332599 --> 0.332057).  Saving model ...\n",
      "152\n",
      "train_loss: 0.33985 valid_loss: 0.33150\n",
      "Validation loss decreased (0.332057 --> 0.331499).  Saving model ...\n",
      "153\n",
      "train_loss: 0.33944 valid_loss: 0.33080\n",
      "Validation loss decreased (0.331499 --> 0.330797).  Saving model ...\n",
      "154\n",
      "train_loss: 0.33825 valid_loss: 0.33012\n",
      "Validation loss decreased (0.330797 --> 0.330118).  Saving model ...\n",
      "155\n",
      "train_loss: 0.33882 valid_loss: 0.32936\n",
      "Validation loss decreased (0.330118 --> 0.329358).  Saving model ...\n",
      "156\n",
      "train_loss: 0.33793 valid_loss: 0.32862\n",
      "Validation loss decreased (0.329358 --> 0.328616).  Saving model ...\n",
      "157\n",
      "train_loss: 0.33663 valid_loss: 0.32822\n",
      "Validation loss decreased (0.328616 --> 0.328222).  Saving model ...\n",
      "158\n",
      "train_loss: 0.33541 valid_loss: 0.32771\n",
      "Validation loss decreased (0.328222 --> 0.327714).  Saving model ...\n",
      "159\n",
      "train_loss: 0.33486 valid_loss: 0.32704\n",
      "Validation loss decreased (0.327714 --> 0.327042).  Saving model ...\n",
      "160\n",
      "train_loss: 0.33469 valid_loss: 0.32645\n",
      "Validation loss decreased (0.327042 --> 0.326450).  Saving model ...\n",
      "161\n",
      "train_loss: 0.33408 valid_loss: 0.32566\n",
      "Validation loss decreased (0.326450 --> 0.325658).  Saving model ...\n",
      "162\n",
      "train_loss: 0.33375 valid_loss: 0.32490\n",
      "Validation loss decreased (0.325658 --> 0.324904).  Saving model ...\n",
      "163\n",
      "train_loss: 0.33250 valid_loss: 0.32433\n",
      "Validation loss decreased (0.324904 --> 0.324330).  Saving model ...\n",
      "164\n",
      "train_loss: 0.33199 valid_loss: 0.32400\n",
      "Validation loss decreased (0.324330 --> 0.324005).  Saving model ...\n",
      "165\n",
      "train_loss: 0.33232 valid_loss: 0.32354\n",
      "Validation loss decreased (0.324005 --> 0.323539).  Saving model ...\n",
      "166\n",
      "train_loss: 0.33108 valid_loss: 0.32247\n",
      "Validation loss decreased (0.323539 --> 0.322469).  Saving model ...\n",
      "167\n",
      "train_loss: 0.33055 valid_loss: 0.32207\n",
      "Validation loss decreased (0.322469 --> 0.322073).  Saving model ...\n",
      "168\n",
      "train_loss: 0.33062 valid_loss: 0.32170\n",
      "Validation loss decreased (0.322073 --> 0.321698).  Saving model ...\n",
      "169\n",
      "train_loss: 0.33027 valid_loss: 0.32104\n",
      "Validation loss decreased (0.321698 --> 0.321037).  Saving model ...\n",
      "170\n",
      "train_loss: 0.32872 valid_loss: 0.32035\n",
      "Validation loss decreased (0.321037 --> 0.320354).  Saving model ...\n",
      "171\n",
      "train_loss: 0.32861 valid_loss: 0.31976\n",
      "Validation loss decreased (0.320354 --> 0.319756).  Saving model ...\n",
      "172\n",
      "train_loss: 0.32645 valid_loss: 0.31967\n",
      "Validation loss decreased (0.319756 --> 0.319675).  Saving model ...\n",
      "173\n",
      "train_loss: 0.32721 valid_loss: 0.31870\n",
      "Validation loss decreased (0.319675 --> 0.318702).  Saving model ...\n",
      "174\n",
      "train_loss: 0.32609 valid_loss: 0.31824\n",
      "Validation loss decreased (0.318702 --> 0.318244).  Saving model ...\n",
      "175\n",
      "train_loss: 0.32658 valid_loss: 0.31796\n",
      "Validation loss decreased (0.318244 --> 0.317958).  Saving model ...\n",
      "176\n",
      "train_loss: 0.32669 valid_loss: 0.31708\n",
      "Validation loss decreased (0.317958 --> 0.317080).  Saving model ...\n",
      "177\n",
      "train_loss: 0.32519 valid_loss: 0.31636\n",
      "Validation loss decreased (0.317080 --> 0.316362).  Saving model ...\n",
      "178\n",
      "train_loss: 0.32368 valid_loss: 0.31587\n",
      "Validation loss decreased (0.316362 --> 0.315870).  Saving model ...\n",
      "179\n",
      "train_loss: 0.32363 valid_loss: 0.31543\n",
      "Validation loss decreased (0.315870 --> 0.315434).  Saving model ...\n",
      "180\n",
      "train_loss: 0.32245 valid_loss: 0.31471\n",
      "Validation loss decreased (0.315434 --> 0.314708).  Saving model ...\n",
      "181\n",
      "train_loss: 0.32194 valid_loss: 0.31434\n",
      "Validation loss decreased (0.314708 --> 0.314344).  Saving model ...\n",
      "182\n",
      "train_loss: 0.32208 valid_loss: 0.31384\n",
      "Validation loss decreased (0.314344 --> 0.313837).  Saving model ...\n",
      "183\n",
      "train_loss: 0.32091 valid_loss: 0.31335\n",
      "Validation loss decreased (0.313837 --> 0.313349).  Saving model ...\n",
      "184\n",
      "train_loss: 0.31961 valid_loss: 0.31278\n",
      "Validation loss decreased (0.313349 --> 0.312780).  Saving model ...\n",
      "185\n",
      "train_loss: 0.31952 valid_loss: 0.31231\n",
      "Validation loss decreased (0.312780 --> 0.312314).  Saving model ...\n",
      "186\n",
      "train_loss: 0.31900 valid_loss: 0.31149\n",
      "Validation loss decreased (0.312314 --> 0.311491).  Saving model ...\n",
      "187\n",
      "train_loss: 0.31842 valid_loss: 0.31111\n",
      "Validation loss decreased (0.311491 --> 0.311115).  Saving model ...\n",
      "188\n",
      "train_loss: 0.31800 valid_loss: 0.31057\n",
      "Validation loss decreased (0.311115 --> 0.310565).  Saving model ...\n",
      "189\n",
      "train_loss: 0.31740 valid_loss: 0.31021\n",
      "Validation loss decreased (0.310565 --> 0.310209).  Saving model ...\n",
      "190\n",
      "train_loss: 0.31701 valid_loss: 0.30985\n",
      "Validation loss decreased (0.310209 --> 0.309854).  Saving model ...\n",
      "191\n",
      "train_loss: 0.31683 valid_loss: 0.30917\n",
      "Validation loss decreased (0.309854 --> 0.309171).  Saving model ...\n",
      "192\n",
      "train_loss: 0.31685 valid_loss: 0.30842\n",
      "Validation loss decreased (0.309171 --> 0.308424).  Saving model ...\n",
      "193\n",
      "train_loss: 0.31549 valid_loss: 0.30854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "194\n",
      "train_loss: 0.31458 valid_loss: 0.30748\n",
      "Validation loss decreased (0.308424 --> 0.307480).  Saving model ...\n",
      "195\n",
      "train_loss: 0.31572 valid_loss: 0.30712\n",
      "Validation loss decreased (0.307480 --> 0.307121).  Saving model ...\n",
      "196\n",
      "train_loss: 0.31369 valid_loss: 0.30676\n",
      "Validation loss decreased (0.307121 --> 0.306758).  Saving model ...\n",
      "197\n",
      "train_loss: 0.31351 valid_loss: 0.30625\n",
      "Validation loss decreased (0.306758 --> 0.306248).  Saving model ...\n",
      "198\n",
      "train_loss: 0.31320 valid_loss: 0.30579\n",
      "Validation loss decreased (0.306248 --> 0.305794).  Saving model ...\n",
      "199\n",
      "train_loss: 0.31220 valid_loss: 0.30549\n",
      "Validation loss decreased (0.305794 --> 0.305492).  Saving model ...\n",
      "200\n",
      "train_loss: 0.31211 valid_loss: 0.30506\n",
      "Validation loss decreased (0.305492 --> 0.305057).  Saving model ...\n",
      "201\n",
      "train_loss: 0.31119 valid_loss: 0.30443\n",
      "Validation loss decreased (0.305057 --> 0.304431).  Saving model ...\n",
      "202\n",
      "train_loss: 0.31153 valid_loss: 0.30393\n",
      "Validation loss decreased (0.304431 --> 0.303928).  Saving model ...\n",
      "203\n",
      "train_loss: 0.30974 valid_loss: 0.30349\n",
      "Validation loss decreased (0.303928 --> 0.303491).  Saving model ...\n",
      "204\n",
      "train_loss: 0.31052 valid_loss: 0.30297\n",
      "Validation loss decreased (0.303491 --> 0.302970).  Saving model ...\n",
      "205\n",
      "train_loss: 0.30981 valid_loss: 0.30251\n",
      "Validation loss decreased (0.302970 --> 0.302509).  Saving model ...\n",
      "206\n",
      "train_loss: 0.31005 valid_loss: 0.30238\n",
      "Validation loss decreased (0.302509 --> 0.302382).  Saving model ...\n",
      "207\n",
      "train_loss: 0.30842 valid_loss: 0.30180\n",
      "Validation loss decreased (0.302382 --> 0.301800).  Saving model ...\n",
      "208\n",
      "train_loss: 0.30871 valid_loss: 0.30149\n",
      "Validation loss decreased (0.301800 --> 0.301495).  Saving model ...\n",
      "209\n",
      "train_loss: 0.30824 valid_loss: 0.30121\n",
      "Validation loss decreased (0.301495 --> 0.301211).  Saving model ...\n",
      "210\n",
      "train_loss: 0.30728 valid_loss: 0.30070\n",
      "Validation loss decreased (0.301211 --> 0.300696).  Saving model ...\n",
      "211\n",
      "train_loss: 0.30638 valid_loss: 0.30001\n",
      "Validation loss decreased (0.300696 --> 0.300006).  Saving model ...\n",
      "212\n",
      "train_loss: 0.30541 valid_loss: 0.29971\n",
      "Validation loss decreased (0.300006 --> 0.299710).  Saving model ...\n",
      "213\n",
      "train_loss: 0.30627 valid_loss: 0.29936\n",
      "Validation loss decreased (0.299710 --> 0.299359).  Saving model ...\n",
      "214\n",
      "train_loss: 0.30653 valid_loss: 0.29891\n",
      "Validation loss decreased (0.299359 --> 0.298914).  Saving model ...\n",
      "215\n",
      "train_loss: 0.30430 valid_loss: 0.29844\n",
      "Validation loss decreased (0.298914 --> 0.298439).  Saving model ...\n",
      "216\n",
      "train_loss: 0.30490 valid_loss: 0.29818\n",
      "Validation loss decreased (0.298439 --> 0.298181).  Saving model ...\n",
      "217\n",
      "train_loss: 0.30567 valid_loss: 0.29764\n",
      "Validation loss decreased (0.298181 --> 0.297644).  Saving model ...\n",
      "218\n",
      "train_loss: 0.30406 valid_loss: 0.29731\n",
      "Validation loss decreased (0.297644 --> 0.297307).  Saving model ...\n",
      "219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.30307 valid_loss: 0.29678\n",
      "Validation loss decreased (0.297307 --> 0.296781).  Saving model ...\n",
      "220\n",
      "train_loss: 0.30257 valid_loss: 0.29639\n",
      "Validation loss decreased (0.296781 --> 0.296393).  Saving model ...\n",
      "221\n",
      "train_loss: 0.30419 valid_loss: 0.29573\n",
      "Validation loss decreased (0.296393 --> 0.295733).  Saving model ...\n",
      "222\n",
      "train_loss: 0.30134 valid_loss: 0.29582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "223\n",
      "train_loss: 0.30216 valid_loss: 0.29544\n",
      "Validation loss decreased (0.295733 --> 0.295444).  Saving model ...\n",
      "224\n",
      "train_loss: 0.30119 valid_loss: 0.29484\n",
      "Validation loss decreased (0.295444 --> 0.294842).  Saving model ...\n",
      "225\n",
      "train_loss: 0.29996 valid_loss: 0.29444\n",
      "Validation loss decreased (0.294842 --> 0.294444).  Saving model ...\n",
      "226\n",
      "train_loss: 0.30116 valid_loss: 0.29416\n",
      "Validation loss decreased (0.294444 --> 0.294155).  Saving model ...\n",
      "227\n",
      "train_loss: 0.29993 valid_loss: 0.29372\n",
      "Validation loss decreased (0.294155 --> 0.293715).  Saving model ...\n",
      "228\n",
      "train_loss: 0.29986 valid_loss: 0.29338\n",
      "Validation loss decreased (0.293715 --> 0.293380).  Saving model ...\n",
      "229\n",
      "train_loss: 0.29792 valid_loss: 0.29303\n",
      "Validation loss decreased (0.293380 --> 0.293027).  Saving model ...\n",
      "230\n",
      "train_loss: 0.29790 valid_loss: 0.29253\n",
      "Validation loss decreased (0.293027 --> 0.292531).  Saving model ...\n",
      "231\n",
      "train_loss: 0.29767 valid_loss: 0.29231\n",
      "Validation loss decreased (0.292531 --> 0.292310).  Saving model ...\n",
      "232\n",
      "train_loss: 0.29715 valid_loss: 0.29178\n",
      "Validation loss decreased (0.292310 --> 0.291780).  Saving model ...\n",
      "233\n",
      "train_loss: 0.29679 valid_loss: 0.29144\n",
      "Validation loss decreased (0.291780 --> 0.291439).  Saving model ...\n",
      "234\n",
      "train_loss: 0.29730 valid_loss: 0.29108\n",
      "Validation loss decreased (0.291439 --> 0.291082).  Saving model ...\n",
      "235\n",
      "train_loss: 0.29653 valid_loss: 0.29078\n",
      "Validation loss decreased (0.291082 --> 0.290777).  Saving model ...\n",
      "236\n",
      "train_loss: 0.29560 valid_loss: 0.29020\n",
      "Validation loss decreased (0.290777 --> 0.290195).  Saving model ...\n",
      "237\n",
      "train_loss: 0.29513 valid_loss: 0.28988\n",
      "Validation loss decreased (0.290195 --> 0.289878).  Saving model ...\n",
      "238\n",
      "train_loss: 0.29534 valid_loss: 0.28968\n",
      "Validation loss decreased (0.289878 --> 0.289678).  Saving model ...\n",
      "239\n",
      "train_loss: 0.29442 valid_loss: 0.28905\n",
      "Validation loss decreased (0.289678 --> 0.289050).  Saving model ...\n",
      "240\n",
      "train_loss: 0.29504 valid_loss: 0.28892\n",
      "Validation loss decreased (0.289050 --> 0.288924).  Saving model ...\n",
      "241\n",
      "train_loss: 0.29308 valid_loss: 0.28841\n",
      "Validation loss decreased (0.288924 --> 0.288414).  Saving model ...\n",
      "242\n",
      "train_loss: 0.29424 valid_loss: 0.28805\n",
      "Validation loss decreased (0.288414 --> 0.288055).  Saving model ...\n",
      "243\n",
      "train_loss: 0.29378 valid_loss: 0.28804\n",
      "Validation loss decreased (0.288055 --> 0.288038).  Saving model ...\n",
      "244\n",
      "train_loss: 0.29320 valid_loss: 0.28744\n",
      "Validation loss decreased (0.288038 --> 0.287436).  Saving model ...\n",
      "245\n",
      "train_loss: 0.29250 valid_loss: 0.28694\n",
      "Validation loss decreased (0.287436 --> 0.286937).  Saving model ...\n",
      "246\n",
      "train_loss: 0.29228 valid_loss: 0.28664\n",
      "Validation loss decreased (0.286937 --> 0.286638).  Saving model ...\n",
      "247\n",
      "train_loss: 0.29161 valid_loss: 0.28633\n",
      "Validation loss decreased (0.286638 --> 0.286335).  Saving model ...\n",
      "248\n",
      "train_loss: 0.29093 valid_loss: 0.28610\n",
      "Validation loss decreased (0.286335 --> 0.286100).  Saving model ...\n",
      "249\n",
      "train_loss: 0.29031 valid_loss: 0.28547\n",
      "Validation loss decreased (0.286100 --> 0.285468).  Saving model ...\n",
      "250\n",
      "train_loss: 0.29067 valid_loss: 0.28532\n",
      "Validation loss decreased (0.285468 --> 0.285318).  Saving model ...\n",
      "251\n",
      "train_loss: 0.28957 valid_loss: 0.28480\n",
      "Validation loss decreased (0.285318 --> 0.284801).  Saving model ...\n",
      "252\n",
      "train_loss: 0.28918 valid_loss: 0.28456\n",
      "Validation loss decreased (0.284801 --> 0.284564).  Saving model ...\n",
      "253\n",
      "train_loss: 0.28893 valid_loss: 0.28432\n",
      "Validation loss decreased (0.284564 --> 0.284316).  Saving model ...\n",
      "254\n",
      "train_loss: 0.28884 valid_loss: 0.28392\n",
      "Validation loss decreased (0.284316 --> 0.283916).  Saving model ...\n",
      "255\n",
      "train_loss: 0.28924 valid_loss: 0.28357\n",
      "Validation loss decreased (0.283916 --> 0.283568).  Saving model ...\n",
      "256\n",
      "train_loss: 0.28710 valid_loss: 0.28318\n",
      "Validation loss decreased (0.283568 --> 0.283182).  Saving model ...\n",
      "257\n",
      "train_loss: 0.28711 valid_loss: 0.28307\n",
      "Validation loss decreased (0.283182 --> 0.283068).  Saving model ...\n",
      "258\n",
      "train_loss: 0.28843 valid_loss: 0.28267\n",
      "Validation loss decreased (0.283068 --> 0.282672).  Saving model ...\n",
      "259\n",
      "train_loss: 0.28704 valid_loss: 0.28223\n",
      "Validation loss decreased (0.282672 --> 0.282228).  Saving model ...\n",
      "260\n",
      "train_loss: 0.28667 valid_loss: 0.28189\n",
      "Validation loss decreased (0.282228 --> 0.281889).  Saving model ...\n",
      "261\n",
      "train_loss: 0.28631 valid_loss: 0.28163\n",
      "Validation loss decreased (0.281889 --> 0.281632).  Saving model ...\n",
      "262\n",
      "train_loss: 0.28573 valid_loss: 0.28112\n",
      "Validation loss decreased (0.281632 --> 0.281115).  Saving model ...\n",
      "263\n",
      "train_loss: 0.28444 valid_loss: 0.28076\n",
      "Validation loss decreased (0.281115 --> 0.280763).  Saving model ...\n",
      "264\n",
      "train_loss: 0.28488 valid_loss: 0.28064\n",
      "Validation loss decreased (0.280763 --> 0.280637).  Saving model ...\n",
      "265\n",
      "train_loss: 0.28391 valid_loss: 0.28007\n",
      "Validation loss decreased (0.280637 --> 0.280066).  Saving model ...\n",
      "266\n",
      "train_loss: 0.28413 valid_loss: 0.27987\n",
      "Validation loss decreased (0.280066 --> 0.279874).  Saving model ...\n",
      "267\n",
      "train_loss: 0.28380 valid_loss: 0.27955\n",
      "Validation loss decreased (0.279874 --> 0.279550).  Saving model ...\n",
      "268\n",
      "train_loss: 0.28398 valid_loss: 0.27914\n",
      "Validation loss decreased (0.279550 --> 0.279136).  Saving model ...\n",
      "269\n",
      "train_loss: 0.28350 valid_loss: 0.27890\n",
      "Validation loss decreased (0.279136 --> 0.278900).  Saving model ...\n",
      "270\n",
      "train_loss: 0.28279 valid_loss: 0.27853\n",
      "Validation loss decreased (0.278900 --> 0.278532).  Saving model ...\n",
      "271\n",
      "train_loss: 0.28327 valid_loss: 0.27836\n",
      "Validation loss decreased (0.278532 --> 0.278359).  Saving model ...\n",
      "272\n",
      "train_loss: 0.28211 valid_loss: 0.27790\n",
      "Validation loss decreased (0.278359 --> 0.277904).  Saving model ...\n",
      "273\n",
      "train_loss: 0.28146 valid_loss: 0.27745\n",
      "Validation loss decreased (0.277904 --> 0.277449).  Saving model ...\n",
      "274\n",
      "train_loss: 0.28145 valid_loss: 0.27746\n",
      "EarlyStopping counter: 1 out of 10\n",
      "275\n",
      "train_loss: 0.28088 valid_loss: 0.27685\n",
      "Validation loss decreased (0.277449 --> 0.276850).  Saving model ...\n",
      "276\n",
      "train_loss: 0.28007 valid_loss: 0.27673\n",
      "Validation loss decreased (0.276850 --> 0.276728).  Saving model ...\n",
      "277\n",
      "train_loss: 0.28023 valid_loss: 0.27620\n",
      "Validation loss decreased (0.276728 --> 0.276201).  Saving model ...\n",
      "278\n",
      "train_loss: 0.27983 valid_loss: 0.27589\n",
      "Validation loss decreased (0.276201 --> 0.275889).  Saving model ...\n",
      "279\n",
      "train_loss: 0.27973 valid_loss: 0.27558\n",
      "Validation loss decreased (0.275889 --> 0.275582).  Saving model ...\n",
      "280\n",
      "train_loss: 0.27953 valid_loss: 0.27559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "281\n",
      "train_loss: 0.27867 valid_loss: 0.27491\n",
      "Validation loss decreased (0.275582 --> 0.274910).  Saving model ...\n",
      "282\n",
      "train_loss: 0.27794 valid_loss: 0.27470\n",
      "Validation loss decreased (0.274910 --> 0.274704).  Saving model ...\n",
      "283\n",
      "train_loss: 0.27848 valid_loss: 0.27464\n",
      "Validation loss decreased (0.274704 --> 0.274636).  Saving model ...\n",
      "284\n",
      "train_loss: 0.27753 valid_loss: 0.27424\n",
      "Validation loss decreased (0.274636 --> 0.274241).  Saving model ...\n",
      "285\n",
      "train_loss: 0.27782 valid_loss: 0.27376\n",
      "Validation loss decreased (0.274241 --> 0.273763).  Saving model ...\n",
      "286\n",
      "train_loss: 0.27702 valid_loss: 0.27337\n",
      "Validation loss decreased (0.273763 --> 0.273366).  Saving model ...\n",
      "287\n",
      "train_loss: 0.27645 valid_loss: 0.27311\n",
      "Validation loss decreased (0.273366 --> 0.273106).  Saving model ...\n",
      "288\n",
      "train_loss: 0.27690 valid_loss: 0.27295\n",
      "Validation loss decreased (0.273106 --> 0.272952).  Saving model ...\n",
      "289\n",
      "train_loss: 0.27607 valid_loss: 0.27268\n",
      "Validation loss decreased (0.272952 --> 0.272678).  Saving model ...\n",
      "290\n",
      "train_loss: 0.27572 valid_loss: 0.27224\n",
      "Validation loss decreased (0.272678 --> 0.272244).  Saving model ...\n",
      "291\n",
      "train_loss: 0.27587 valid_loss: 0.27193\n",
      "Validation loss decreased (0.272244 --> 0.271928).  Saving model ...\n",
      "292\n",
      "train_loss: 0.27523 valid_loss: 0.27177\n",
      "Validation loss decreased (0.271928 --> 0.271766).  Saving model ...\n",
      "293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.27414 valid_loss: 0.27140\n",
      "Validation loss decreased (0.271766 --> 0.271397).  Saving model ...\n",
      "294\n",
      "train_loss: 0.27401 valid_loss: 0.27111\n",
      "Validation loss decreased (0.271397 --> 0.271114).  Saving model ...\n",
      "295\n",
      "train_loss: 0.27398 valid_loss: 0.27077\n",
      "Validation loss decreased (0.271114 --> 0.270769).  Saving model ...\n",
      "296\n",
      "train_loss: 0.27345 valid_loss: 0.27040\n",
      "Validation loss decreased (0.270769 --> 0.270403).  Saving model ...\n",
      "297\n",
      "train_loss: 0.27313 valid_loss: 0.27025\n",
      "Validation loss decreased (0.270403 --> 0.270246).  Saving model ...\n",
      "298\n",
      "train_loss: 0.27289 valid_loss: 0.26986\n",
      "Validation loss decreased (0.270246 --> 0.269856).  Saving model ...\n",
      "299\n",
      "train_loss: 0.27245 valid_loss: 0.26973\n",
      "Validation loss decreased (0.269856 --> 0.269731).  Saving model ...\n",
      "300\n",
      "train_loss: 0.27283 valid_loss: 0.26932\n",
      "Validation loss decreased (0.269731 --> 0.269323).  Saving model ...\n",
      "301\n",
      "train_loss: 0.27256 valid_loss: 0.26909\n",
      "Validation loss decreased (0.269323 --> 0.269091).  Saving model ...\n",
      "302\n",
      "train_loss: 0.27190 valid_loss: 0.26851\n",
      "Validation loss decreased (0.269091 --> 0.268510).  Saving model ...\n",
      "303\n",
      "train_loss: 0.27099 valid_loss: 0.26854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "304\n",
      "train_loss: 0.27132 valid_loss: 0.26837\n",
      "Validation loss decreased (0.268510 --> 0.268375).  Saving model ...\n",
      "305\n",
      "train_loss: 0.27165 valid_loss: 0.26786\n",
      "Validation loss decreased (0.268375 --> 0.267858).  Saving model ...\n",
      "306\n",
      "train_loss: 0.27162 valid_loss: 0.26762\n",
      "Validation loss decreased (0.267858 --> 0.267619).  Saving model ...\n",
      "307\n",
      "train_loss: 0.26962 valid_loss: 0.26731\n",
      "Validation loss decreased (0.267619 --> 0.267305).  Saving model ...\n",
      "308\n",
      "train_loss: 0.26953 valid_loss: 0.26700\n",
      "Validation loss decreased (0.267305 --> 0.267005).  Saving model ...\n",
      "309\n",
      "train_loss: 0.26953 valid_loss: 0.26670\n",
      "Validation loss decreased (0.267005 --> 0.266701).  Saving model ...\n",
      "310\n",
      "train_loss: 0.26881 valid_loss: 0.26633\n",
      "Validation loss decreased (0.266701 --> 0.266328).  Saving model ...\n",
      "311\n",
      "train_loss: 0.26909 valid_loss: 0.26627\n",
      "Validation loss decreased (0.266328 --> 0.266265).  Saving model ...\n",
      "312\n",
      "train_loss: 0.26817 valid_loss: 0.26563\n",
      "Validation loss decreased (0.266265 --> 0.265628).  Saving model ...\n",
      "313\n",
      "train_loss: 0.26903 valid_loss: 0.26559\n",
      "Validation loss decreased (0.265628 --> 0.265587).  Saving model ...\n",
      "314\n",
      "train_loss: 0.26769 valid_loss: 0.26511\n",
      "Validation loss decreased (0.265587 --> 0.265107).  Saving model ...\n",
      "315\n",
      "train_loss: 0.26833 valid_loss: 0.26488\n",
      "Validation loss decreased (0.265107 --> 0.264875).  Saving model ...\n",
      "316\n",
      "train_loss: 0.26724 valid_loss: 0.26466\n",
      "Validation loss decreased (0.264875 --> 0.264660).  Saving model ...\n",
      "317\n",
      "train_loss: 0.26652 valid_loss: 0.26435\n",
      "Validation loss decreased (0.264660 --> 0.264352).  Saving model ...\n",
      "318\n",
      "train_loss: 0.26615 valid_loss: 0.26414\n",
      "Validation loss decreased (0.264352 --> 0.264136).  Saving model ...\n",
      "319\n",
      "train_loss: 0.26681 valid_loss: 0.26381\n",
      "Validation loss decreased (0.264136 --> 0.263810).  Saving model ...\n",
      "320\n",
      "train_loss: 0.26650 valid_loss: 0.26352\n",
      "Validation loss decreased (0.263810 --> 0.263518).  Saving model ...\n",
      "321\n",
      "train_loss: 0.26581 valid_loss: 0.26317\n",
      "Validation loss decreased (0.263518 --> 0.263173).  Saving model ...\n",
      "322\n",
      "train_loss: 0.26542 valid_loss: 0.26313\n",
      "Validation loss decreased (0.263173 --> 0.263125).  Saving model ...\n",
      "323\n",
      "train_loss: 0.26476 valid_loss: 0.26267\n",
      "Validation loss decreased (0.263125 --> 0.262671).  Saving model ...\n",
      "324\n",
      "train_loss: 0.26495 valid_loss: 0.26253\n",
      "Validation loss decreased (0.262671 --> 0.262526).  Saving model ...\n",
      "325\n",
      "train_loss: 0.26446 valid_loss: 0.26221\n",
      "Validation loss decreased (0.262526 --> 0.262214).  Saving model ...\n",
      "326\n",
      "train_loss: 0.26448 valid_loss: 0.26191\n",
      "Validation loss decreased (0.262214 --> 0.261912).  Saving model ...\n",
      "327\n",
      "train_loss: 0.26324 valid_loss: 0.26167\n",
      "Validation loss decreased (0.261912 --> 0.261667).  Saving model ...\n",
      "328\n",
      "train_loss: 0.26372 valid_loss: 0.26137\n",
      "Validation loss decreased (0.261667 --> 0.261368).  Saving model ...\n",
      "329\n",
      "train_loss: 0.26301 valid_loss: 0.26101\n",
      "Validation loss decreased (0.261368 --> 0.261005).  Saving model ...\n",
      "330\n",
      "train_loss: 0.26353 valid_loss: 0.26078\n",
      "Validation loss decreased (0.261005 --> 0.260780).  Saving model ...\n",
      "331\n",
      "train_loss: 0.26329 valid_loss: 0.26062\n",
      "Validation loss decreased (0.260780 --> 0.260621).  Saving model ...\n",
      "332\n",
      "train_loss: 0.26276 valid_loss: 0.26066\n",
      "EarlyStopping counter: 1 out of 10\n",
      "333\n",
      "train_loss: 0.26194 valid_loss: 0.25999\n",
      "Validation loss decreased (0.260621 --> 0.259986).  Saving model ...\n",
      "334\n",
      "train_loss: 0.26143 valid_loss: 0.25953\n",
      "Validation loss decreased (0.259986 --> 0.259526).  Saving model ...\n",
      "335\n",
      "train_loss: 0.26143 valid_loss: 0.25945\n",
      "Validation loss decreased (0.259526 --> 0.259445).  Saving model ...\n",
      "336\n",
      "train_loss: 0.26085 valid_loss: 0.25928\n",
      "Validation loss decreased (0.259445 --> 0.259283).  Saving model ...\n",
      "337\n",
      "train_loss: 0.26197 valid_loss: 0.25890\n",
      "Validation loss decreased (0.259283 --> 0.258896).  Saving model ...\n",
      "338\n",
      "train_loss: 0.26013 valid_loss: 0.25859\n",
      "Validation loss decreased (0.258896 --> 0.258585).  Saving model ...\n",
      "339\n",
      "train_loss: 0.26111 valid_loss: 0.25838\n",
      "Validation loss decreased (0.258585 --> 0.258380).  Saving model ...\n",
      "340\n",
      "train_loss: 0.25954 valid_loss: 0.25806\n",
      "Validation loss decreased (0.258380 --> 0.258063).  Saving model ...\n",
      "341\n",
      "train_loss: 0.25899 valid_loss: 0.25779\n",
      "Validation loss decreased (0.258063 --> 0.257789).  Saving model ...\n",
      "342\n",
      "train_loss: 0.25949 valid_loss: 0.25754\n",
      "Validation loss decreased (0.257789 --> 0.257536).  Saving model ...\n",
      "343\n",
      "train_loss: 0.25947 valid_loss: 0.25743\n",
      "Validation loss decreased (0.257536 --> 0.257429).  Saving model ...\n",
      "344\n",
      "train_loss: 0.25998 valid_loss: 0.25703\n",
      "Validation loss decreased (0.257429 --> 0.257025).  Saving model ...\n",
      "345\n",
      "train_loss: 0.25800 valid_loss: 0.25686\n",
      "Validation loss decreased (0.257025 --> 0.256862).  Saving model ...\n",
      "346\n",
      "train_loss: 0.25872 valid_loss: 0.25658\n",
      "Validation loss decreased (0.256862 --> 0.256575).  Saving model ...\n",
      "347\n",
      "train_loss: 0.25754 valid_loss: 0.25624\n",
      "Validation loss decreased (0.256575 --> 0.256243).  Saving model ...\n",
      "348\n",
      "train_loss: 0.25863 valid_loss: 0.25599\n",
      "Validation loss decreased (0.256243 --> 0.255986).  Saving model ...\n",
      "349\n",
      "train_loss: 0.25755 valid_loss: 0.25571\n",
      "Validation loss decreased (0.255986 --> 0.255712).  Saving model ...\n",
      "350\n",
      "train_loss: 0.25748 valid_loss: 0.25534\n",
      "Validation loss decreased (0.255712 --> 0.255337).  Saving model ...\n",
      "351\n",
      "train_loss: 0.25646 valid_loss: 0.25520\n",
      "Validation loss decreased (0.255337 --> 0.255199).  Saving model ...\n",
      "352\n",
      "train_loss: 0.25581 valid_loss: 0.25502\n",
      "Validation loss decreased (0.255199 --> 0.255019).  Saving model ...\n",
      "353\n",
      "train_loss: 0.25596 valid_loss: 0.25484\n",
      "Validation loss decreased (0.255019 --> 0.254842).  Saving model ...\n",
      "354\n",
      "train_loss: 0.25576 valid_loss: 0.25443\n",
      "Validation loss decreased (0.254842 --> 0.254435).  Saving model ...\n",
      "355\n",
      "train_loss: 0.25501 valid_loss: 0.25415\n",
      "Validation loss decreased (0.254435 --> 0.254151).  Saving model ...\n",
      "356\n",
      "train_loss: 0.25552 valid_loss: 0.25406\n",
      "Validation loss decreased (0.254151 --> 0.254058).  Saving model ...\n",
      "357\n",
      "train_loss: 0.25476 valid_loss: 0.25358\n",
      "Validation loss decreased (0.254058 --> 0.253578).  Saving model ...\n",
      "358\n",
      "train_loss: 0.25512 valid_loss: 0.25358\n",
      "Validation loss decreased (0.253578 --> 0.253578).  Saving model ...\n",
      "359\n",
      "train_loss: 0.25426 valid_loss: 0.25309\n",
      "Validation loss decreased (0.253578 --> 0.253087).  Saving model ...\n",
      "360\n",
      "train_loss: 0.25468 valid_loss: 0.25291\n",
      "Validation loss decreased (0.253087 --> 0.252905).  Saving model ...\n",
      "361\n",
      "train_loss: 0.25353 valid_loss: 0.25259\n",
      "Validation loss decreased (0.252905 --> 0.252588).  Saving model ...\n",
      "362\n",
      "train_loss: 0.25372 valid_loss: 0.25226\n",
      "Validation loss decreased (0.252588 --> 0.252256).  Saving model ...\n",
      "363\n",
      "train_loss: 0.25469 valid_loss: 0.25206\n",
      "Validation loss decreased (0.252256 --> 0.252060).  Saving model ...\n",
      "364\n",
      "train_loss: 0.25284 valid_loss: 0.25204\n",
      "Validation loss decreased (0.252060 --> 0.252041).  Saving model ...\n",
      "365\n",
      "train_loss: 0.25273 valid_loss: 0.25155\n",
      "Validation loss decreased (0.252041 --> 0.251547).  Saving model ...\n",
      "366\n",
      "train_loss: 0.25241 valid_loss: 0.25154\n",
      "Validation loss decreased (0.251547 --> 0.251545).  Saving model ...\n",
      "367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.25305 valid_loss: 0.25126\n",
      "Validation loss decreased (0.251545 --> 0.251263).  Saving model ...\n",
      "368\n",
      "train_loss: 0.25203 valid_loss: 0.25094\n",
      "Validation loss decreased (0.251263 --> 0.250936).  Saving model ...\n",
      "369\n",
      "train_loss: 0.25130 valid_loss: 0.25066\n",
      "Validation loss decreased (0.250936 --> 0.250657).  Saving model ...\n",
      "370\n",
      "train_loss: 0.25238 valid_loss: 0.25048\n",
      "Validation loss decreased (0.250657 --> 0.250484).  Saving model ...\n",
      "371\n",
      "train_loss: 0.25112 valid_loss: 0.25010\n",
      "Validation loss decreased (0.250484 --> 0.250101).  Saving model ...\n",
      "372\n",
      "train_loss: 0.25033 valid_loss: 0.24972\n",
      "Validation loss decreased (0.250101 --> 0.249718).  Saving model ...\n",
      "373\n",
      "train_loss: 0.25056 valid_loss: 0.24949\n",
      "Validation loss decreased (0.249718 --> 0.249489).  Saving model ...\n",
      "374\n",
      "train_loss: 0.24981 valid_loss: 0.24929\n",
      "Validation loss decreased (0.249489 --> 0.249291).  Saving model ...\n",
      "375\n",
      "train_loss: 0.24940 valid_loss: 0.24905\n",
      "Validation loss decreased (0.249291 --> 0.249054).  Saving model ...\n",
      "376\n",
      "train_loss: 0.24928 valid_loss: 0.24886\n",
      "Validation loss decreased (0.249054 --> 0.248858).  Saving model ...\n",
      "377\n",
      "train_loss: 0.25091 valid_loss: 0.24870\n",
      "Validation loss decreased (0.248858 --> 0.248704).  Saving model ...\n",
      "378\n",
      "train_loss: 0.24979 valid_loss: 0.24877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "379\n",
      "train_loss: 0.24888 valid_loss: 0.24850\n",
      "Validation loss decreased (0.248704 --> 0.248503).  Saving model ...\n",
      "380\n",
      "train_loss: 0.24888 valid_loss: 0.24794\n",
      "Validation loss decreased (0.248503 --> 0.247944).  Saving model ...\n",
      "381\n",
      "train_loss: 0.24880 valid_loss: 0.24754\n",
      "Validation loss decreased (0.247944 --> 0.247536).  Saving model ...\n",
      "382\n",
      "train_loss: 0.24775 valid_loss: 0.24747\n",
      "Validation loss decreased (0.247536 --> 0.247466).  Saving model ...\n",
      "383\n",
      "train_loss: 0.24754 valid_loss: 0.24725\n",
      "Validation loss decreased (0.247466 --> 0.247252).  Saving model ...\n",
      "384\n",
      "train_loss: 0.24743 valid_loss: 0.24691\n",
      "Validation loss decreased (0.247252 --> 0.246913).  Saving model ...\n",
      "385\n",
      "train_loss: 0.24687 valid_loss: 0.24669\n",
      "Validation loss decreased (0.246913 --> 0.246695).  Saving model ...\n",
      "386\n",
      "train_loss: 0.24681 valid_loss: 0.24645\n",
      "Validation loss decreased (0.246695 --> 0.246453).  Saving model ...\n",
      "387\n",
      "train_loss: 0.24675 valid_loss: 0.24631\n",
      "Validation loss decreased (0.246453 --> 0.246305).  Saving model ...\n",
      "388\n",
      "train_loss: 0.24587 valid_loss: 0.24591\n",
      "Validation loss decreased (0.246305 --> 0.245905).  Saving model ...\n",
      "389\n",
      "train_loss: 0.24613 valid_loss: 0.24568\n",
      "Validation loss decreased (0.245905 --> 0.245684).  Saving model ...\n",
      "390\n",
      "train_loss: 0.24682 valid_loss: 0.24528\n",
      "Validation loss decreased (0.245684 --> 0.245280).  Saving model ...\n",
      "391\n",
      "train_loss: 0.24500 valid_loss: 0.24515\n",
      "Validation loss decreased (0.245280 --> 0.245152).  Saving model ...\n",
      "392\n",
      "train_loss: 0.24566 valid_loss: 0.24500\n",
      "Validation loss decreased (0.245152 --> 0.245003).  Saving model ...\n",
      "393\n",
      "train_loss: 0.24518 valid_loss: 0.24471\n",
      "Validation loss decreased (0.245003 --> 0.244706).  Saving model ...\n",
      "394\n",
      "train_loss: 0.24480 valid_loss: 0.24457\n",
      "Validation loss decreased (0.244706 --> 0.244566).  Saving model ...\n",
      "395\n",
      "train_loss: 0.24480 valid_loss: 0.24427\n",
      "Validation loss decreased (0.244566 --> 0.244271).  Saving model ...\n",
      "396\n",
      "train_loss: 0.24403 valid_loss: 0.24401\n",
      "Validation loss decreased (0.244271 --> 0.244009).  Saving model ...\n",
      "397\n",
      "train_loss: 0.24369 valid_loss: 0.24372\n",
      "Validation loss decreased (0.244009 --> 0.243718).  Saving model ...\n",
      "398\n",
      "train_loss: 0.24354 valid_loss: 0.24347\n",
      "Validation loss decreased (0.243718 --> 0.243465).  Saving model ...\n",
      "399\n",
      "train_loss: 0.24357 valid_loss: 0.24328\n",
      "Validation loss decreased (0.243465 --> 0.243284).  Saving model ...\n",
      "400\n",
      "train_loss: 0.24260 valid_loss: 0.24324\n",
      "Validation loss decreased (0.243284 --> 0.243242).  Saving model ...\n",
      "401\n",
      "train_loss: 0.24228 valid_loss: 0.24272\n",
      "Validation loss decreased (0.243242 --> 0.242724).  Saving model ...\n",
      "402\n",
      "train_loss: 0.24264 valid_loss: 0.24254\n",
      "Validation loss decreased (0.242724 --> 0.242541).  Saving model ...\n",
      "403\n",
      "train_loss: 0.24191 valid_loss: 0.24238\n",
      "Validation loss decreased (0.242541 --> 0.242377).  Saving model ...\n",
      "404\n",
      "train_loss: 0.24222 valid_loss: 0.24208\n",
      "Validation loss decreased (0.242377 --> 0.242083).  Saving model ...\n",
      "405\n",
      "train_loss: 0.24207 valid_loss: 0.24186\n",
      "Validation loss decreased (0.242083 --> 0.241861).  Saving model ...\n",
      "406\n",
      "train_loss: 0.24137 valid_loss: 0.24168\n",
      "Validation loss decreased (0.241861 --> 0.241683).  Saving model ...\n",
      "407\n",
      "train_loss: 0.24104 valid_loss: 0.24129\n",
      "Validation loss decreased (0.241683 --> 0.241286).  Saving model ...\n",
      "408\n",
      "train_loss: 0.24177 valid_loss: 0.24102\n",
      "Validation loss decreased (0.241286 --> 0.241020).  Saving model ...\n",
      "409\n",
      "train_loss: 0.24136 valid_loss: 0.24103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "410\n",
      "train_loss: 0.24013 valid_loss: 0.24070\n",
      "Validation loss decreased (0.241020 --> 0.240702).  Saving model ...\n",
      "411\n",
      "train_loss: 0.24041 valid_loss: 0.24034\n",
      "Validation loss decreased (0.240702 --> 0.240338).  Saving model ...\n",
      "412\n",
      "train_loss: 0.24034 valid_loss: 0.24013\n",
      "Validation loss decreased (0.240338 --> 0.240131).  Saving model ...\n",
      "413\n",
      "train_loss: 0.24047 valid_loss: 0.23984\n",
      "Validation loss decreased (0.240131 --> 0.239845).  Saving model ...\n",
      "414\n",
      "train_loss: 0.23994 valid_loss: 0.23972\n",
      "Validation loss decreased (0.239845 --> 0.239717).  Saving model ...\n",
      "415\n",
      "train_loss: 0.23916 valid_loss: 0.23957\n",
      "Validation loss decreased (0.239717 --> 0.239568).  Saving model ...\n",
      "416\n",
      "train_loss: 0.23877 valid_loss: 0.23933\n",
      "Validation loss decreased (0.239568 --> 0.239335).  Saving model ...\n",
      "417\n",
      "train_loss: 0.23866 valid_loss: 0.23908\n",
      "Validation loss decreased (0.239335 --> 0.239081).  Saving model ...\n",
      "418\n",
      "train_loss: 0.23885 valid_loss: 0.23877\n",
      "Validation loss decreased (0.239081 --> 0.238770).  Saving model ...\n",
      "419\n",
      "train_loss: 0.23773 valid_loss: 0.23855\n",
      "Validation loss decreased (0.238770 --> 0.238547).  Saving model ...\n",
      "420\n",
      "train_loss: 0.23795 valid_loss: 0.23849\n",
      "Validation loss decreased (0.238547 --> 0.238494).  Saving model ...\n",
      "421\n",
      "train_loss: 0.23688 valid_loss: 0.23804\n",
      "Validation loss decreased (0.238494 --> 0.238039).  Saving model ...\n",
      "422\n",
      "train_loss: 0.23734 valid_loss: 0.23801\n",
      "Validation loss decreased (0.238039 --> 0.238012).  Saving model ...\n",
      "423\n",
      "train_loss: 0.23664 valid_loss: 0.23779\n",
      "Validation loss decreased (0.238012 --> 0.237793).  Saving model ...\n",
      "424\n",
      "train_loss: 0.23749 valid_loss: 0.23739\n",
      "Validation loss decreased (0.237793 --> 0.237393).  Saving model ...\n",
      "425\n",
      "train_loss: 0.23691 valid_loss: 0.23709\n",
      "Validation loss decreased (0.237393 --> 0.237093).  Saving model ...\n",
      "426\n",
      "train_loss: 0.23651 valid_loss: 0.23710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "427\n",
      "train_loss: 0.23657 valid_loss: 0.23665\n",
      "Validation loss decreased (0.237093 --> 0.236649).  Saving model ...\n",
      "428\n",
      "train_loss: 0.23543 valid_loss: 0.23639\n",
      "Validation loss decreased (0.236649 --> 0.236390).  Saving model ...\n",
      "429\n",
      "train_loss: 0.23582 valid_loss: 0.23621\n",
      "Validation loss decreased (0.236390 --> 0.236210).  Saving model ...\n",
      "430\n",
      "train_loss: 0.23531 valid_loss: 0.23590\n",
      "Validation loss decreased (0.236210 --> 0.235898).  Saving model ...\n",
      "431\n",
      "train_loss: 0.23531 valid_loss: 0.23566\n",
      "Validation loss decreased (0.235898 --> 0.235663).  Saving model ...\n",
      "432\n",
      "train_loss: 0.23413 valid_loss: 0.23557\n",
      "Validation loss decreased (0.235663 --> 0.235571).  Saving model ...\n",
      "433\n",
      "train_loss: 0.23438 valid_loss: 0.23530\n",
      "Validation loss decreased (0.235571 --> 0.235301).  Saving model ...\n",
      "434\n",
      "train_loss: 0.23376 valid_loss: 0.23498\n",
      "Validation loss decreased (0.235301 --> 0.234983).  Saving model ...\n",
      "435\n",
      "train_loss: 0.23429 valid_loss: 0.23492\n",
      "Validation loss decreased (0.234983 --> 0.234918).  Saving model ...\n",
      "436\n",
      "train_loss: 0.23385 valid_loss: 0.23464\n",
      "Validation loss decreased (0.234918 --> 0.234638).  Saving model ...\n",
      "437\n",
      "train_loss: 0.23331 valid_loss: 0.23439\n",
      "Validation loss decreased (0.234638 --> 0.234388).  Saving model ...\n",
      "438\n",
      "train_loss: 0.23361 valid_loss: 0.23415\n",
      "Validation loss decreased (0.234388 --> 0.234150).  Saving model ...\n",
      "439\n",
      "train_loss: 0.23380 valid_loss: 0.23382\n",
      "Validation loss decreased (0.234150 --> 0.233823).  Saving model ...\n",
      "440\n",
      "train_loss: 0.23292 valid_loss: 0.23356\n",
      "Validation loss decreased (0.233823 --> 0.233562).  Saving model ...\n",
      "441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.23253 valid_loss: 0.23343\n",
      "Validation loss decreased (0.233562 --> 0.233427).  Saving model ...\n",
      "442\n",
      "train_loss: 0.23345 valid_loss: 0.23306\n",
      "Validation loss decreased (0.233427 --> 0.233056).  Saving model ...\n",
      "443\n",
      "train_loss: 0.23181 valid_loss: 0.23313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "444\n",
      "train_loss: 0.23202 valid_loss: 0.23262\n",
      "Validation loss decreased (0.233056 --> 0.232615).  Saving model ...\n",
      "445\n",
      "train_loss: 0.23225 valid_loss: 0.23246\n",
      "Validation loss decreased (0.232615 --> 0.232458).  Saving model ...\n",
      "446\n",
      "train_loss: 0.23204 valid_loss: 0.23234\n",
      "Validation loss decreased (0.232458 --> 0.232338).  Saving model ...\n",
      "447\n",
      "train_loss: 0.23168 valid_loss: 0.23203\n",
      "Validation loss decreased (0.232338 --> 0.232033).  Saving model ...\n",
      "448\n",
      "train_loss: 0.23093 valid_loss: 0.23195\n",
      "Validation loss decreased (0.232033 --> 0.231948).  Saving model ...\n",
      "449\n",
      "train_loss: 0.23096 valid_loss: 0.23163\n",
      "Validation loss decreased (0.231948 --> 0.231633).  Saving model ...\n",
      "450\n",
      "train_loss: 0.22938 valid_loss: 0.23149\n",
      "Validation loss decreased (0.231633 --> 0.231494).  Saving model ...\n",
      "451\n",
      "train_loss: 0.22966 valid_loss: 0.23119\n",
      "Validation loss decreased (0.231494 --> 0.231195).  Saving model ...\n",
      "452\n",
      "train_loss: 0.23031 valid_loss: 0.23091\n",
      "Validation loss decreased (0.231195 --> 0.230907).  Saving model ...\n",
      "453\n",
      "train_loss: 0.23022 valid_loss: 0.23078\n",
      "Validation loss decreased (0.230907 --> 0.230784).  Saving model ...\n",
      "454\n",
      "train_loss: 0.22919 valid_loss: 0.23067\n",
      "Validation loss decreased (0.230784 --> 0.230670).  Saving model ...\n",
      "455\n",
      "train_loss: 0.22902 valid_loss: 0.23028\n",
      "Validation loss decreased (0.230670 --> 0.230276).  Saving model ...\n",
      "456\n",
      "train_loss: 0.22801 valid_loss: 0.23017\n",
      "Validation loss decreased (0.230276 --> 0.230170).  Saving model ...\n",
      "457\n",
      "train_loss: 0.22824 valid_loss: 0.22987\n",
      "Validation loss decreased (0.230170 --> 0.229875).  Saving model ...\n",
      "458\n",
      "train_loss: 0.22872 valid_loss: 0.22955\n",
      "Validation loss decreased (0.229875 --> 0.229546).  Saving model ...\n",
      "459\n",
      "train_loss: 0.22820 valid_loss: 0.22941\n",
      "Validation loss decreased (0.229546 --> 0.229410).  Saving model ...\n",
      "460\n",
      "train_loss: 0.22697 valid_loss: 0.22915\n",
      "Validation loss decreased (0.229410 --> 0.229153).  Saving model ...\n",
      "461\n",
      "train_loss: 0.22860 valid_loss: 0.22899\n",
      "Validation loss decreased (0.229153 --> 0.228991).  Saving model ...\n",
      "462\n",
      "train_loss: 0.22888 valid_loss: 0.22894\n",
      "Validation loss decreased (0.228991 --> 0.228941).  Saving model ...\n",
      "463\n",
      "train_loss: 0.22757 valid_loss: 0.22871\n",
      "Validation loss decreased (0.228941 --> 0.228712).  Saving model ...\n",
      "464\n",
      "train_loss: 0.22628 valid_loss: 0.22830\n",
      "Validation loss decreased (0.228712 --> 0.228302).  Saving model ...\n",
      "465\n",
      "train_loss: 0.22575 valid_loss: 0.22824\n",
      "Validation loss decreased (0.228302 --> 0.228236).  Saving model ...\n",
      "466\n",
      "train_loss: 0.22624 valid_loss: 0.22795\n",
      "Validation loss decreased (0.228236 --> 0.227946).  Saving model ...\n",
      "467\n",
      "train_loss: 0.22651 valid_loss: 0.22768\n",
      "Validation loss decreased (0.227946 --> 0.227684).  Saving model ...\n",
      "468\n",
      "train_loss: 0.22590 valid_loss: 0.22744\n",
      "Validation loss decreased (0.227684 --> 0.227444).  Saving model ...\n",
      "469\n",
      "train_loss: 0.22640 valid_loss: 0.22710\n",
      "Validation loss decreased (0.227444 --> 0.227095).  Saving model ...\n",
      "470\n",
      "train_loss: 0.22485 valid_loss: 0.22700\n",
      "Validation loss decreased (0.227095 --> 0.226999).  Saving model ...\n",
      "471\n",
      "train_loss: 0.22561 valid_loss: 0.22679\n",
      "Validation loss decreased (0.226999 --> 0.226787).  Saving model ...\n",
      "472\n",
      "train_loss: 0.22506 valid_loss: 0.22643\n",
      "Validation loss decreased (0.226787 --> 0.226426).  Saving model ...\n",
      "473\n",
      "train_loss: 0.22431 valid_loss: 0.22636\n",
      "Validation loss decreased (0.226426 --> 0.226364).  Saving model ...\n",
      "474\n",
      "train_loss: 0.22431 valid_loss: 0.22617\n",
      "Validation loss decreased (0.226364 --> 0.226171).  Saving model ...\n",
      "475\n",
      "train_loss: 0.22384 valid_loss: 0.22589\n",
      "Validation loss decreased (0.226171 --> 0.225888).  Saving model ...\n",
      "476\n",
      "train_loss: 0.22338 valid_loss: 0.22566\n",
      "Validation loss decreased (0.225888 --> 0.225656).  Saving model ...\n",
      "477\n",
      "train_loss: 0.22314 valid_loss: 0.22550\n",
      "Validation loss decreased (0.225656 --> 0.225503).  Saving model ...\n",
      "478\n",
      "train_loss: 0.22376 valid_loss: 0.22524\n",
      "Validation loss decreased (0.225503 --> 0.225244).  Saving model ...\n",
      "479\n",
      "train_loss: 0.22279 valid_loss: 0.22506\n",
      "Validation loss decreased (0.225244 --> 0.225064).  Saving model ...\n",
      "480\n",
      "train_loss: 0.22273 valid_loss: 0.22482\n",
      "Validation loss decreased (0.225064 --> 0.224821).  Saving model ...\n",
      "481\n",
      "train_loss: 0.22270 valid_loss: 0.22468\n",
      "Validation loss decreased (0.224821 --> 0.224679).  Saving model ...\n",
      "482\n",
      "train_loss: 0.22182 valid_loss: 0.22449\n",
      "Validation loss decreased (0.224679 --> 0.224485).  Saving model ...\n",
      "483\n",
      "train_loss: 0.22247 valid_loss: 0.22424\n",
      "Validation loss decreased (0.224485 --> 0.224244).  Saving model ...\n",
      "484\n",
      "train_loss: 0.22142 valid_loss: 0.22415\n",
      "Validation loss decreased (0.224244 --> 0.224151).  Saving model ...\n",
      "485\n",
      "train_loss: 0.22131 valid_loss: 0.22379\n",
      "Validation loss decreased (0.224151 --> 0.223786).  Saving model ...\n",
      "486\n",
      "train_loss: 0.22159 valid_loss: 0.22361\n",
      "Validation loss decreased (0.223786 --> 0.223611).  Saving model ...\n",
      "487\n",
      "train_loss: 0.22211 valid_loss: 0.22345\n",
      "Validation loss decreased (0.223611 --> 0.223450).  Saving model ...\n",
      "488\n",
      "train_loss: 0.22122 valid_loss: 0.22313\n",
      "Validation loss decreased (0.223450 --> 0.223128).  Saving model ...\n",
      "489\n",
      "train_loss: 0.22096 valid_loss: 0.22286\n",
      "Validation loss decreased (0.223128 --> 0.222858).  Saving model ...\n",
      "490\n",
      "train_loss: 0.22059 valid_loss: 0.22271\n",
      "Validation loss decreased (0.222858 --> 0.222707).  Saving model ...\n",
      "491\n",
      "train_loss: 0.21980 valid_loss: 0.22250\n",
      "Validation loss decreased (0.222707 --> 0.222505).  Saving model ...\n",
      "492\n",
      "train_loss: 0.22047 valid_loss: 0.22245\n",
      "Validation loss decreased (0.222505 --> 0.222449).  Saving model ...\n",
      "493\n",
      "train_loss: 0.21990 valid_loss: 0.22216\n",
      "Validation loss decreased (0.222449 --> 0.222158).  Saving model ...\n",
      "494\n",
      "train_loss: 0.21967 valid_loss: 0.22186\n",
      "Validation loss decreased (0.222158 --> 0.221863).  Saving model ...\n",
      "495\n",
      "train_loss: 0.21958 valid_loss: 0.22154\n",
      "Validation loss decreased (0.221863 --> 0.221539).  Saving model ...\n",
      "496\n",
      "train_loss: 0.21870 valid_loss: 0.22140\n",
      "Validation loss decreased (0.221539 --> 0.221398).  Saving model ...\n",
      "497\n",
      "train_loss: 0.21855 valid_loss: 0.22125\n",
      "Validation loss decreased (0.221398 --> 0.221245).  Saving model ...\n",
      "498\n",
      "train_loss: 0.21887 valid_loss: 0.22114\n",
      "Validation loss decreased (0.221245 --> 0.221144).  Saving model ...\n",
      "499\n",
      "train_loss: 0.21826 valid_loss: 0.22070\n",
      "Validation loss decreased (0.221144 --> 0.220705).  Saving model ...\n",
      "500\n",
      "train_loss: 0.21806 valid_loss: 0.22055\n",
      "Validation loss decreased (0.220705 --> 0.220552).  Saving model ...\n",
      "501\n",
      "train_loss: 0.21727 valid_loss: 0.22036\n",
      "Validation loss decreased (0.220552 --> 0.220356).  Saving model ...\n",
      "502\n",
      "train_loss: 0.21765 valid_loss: 0.22020\n",
      "Validation loss decreased (0.220356 --> 0.220197).  Saving model ...\n",
      "503\n",
      "train_loss: 0.21750 valid_loss: 0.22000\n",
      "Validation loss decreased (0.220197 --> 0.219998).  Saving model ...\n",
      "504\n",
      "train_loss: 0.21641 valid_loss: 0.21976\n",
      "Validation loss decreased (0.219998 --> 0.219756).  Saving model ...\n",
      "505\n",
      "train_loss: 0.21648 valid_loss: 0.21961\n",
      "Validation loss decreased (0.219756 --> 0.219605).  Saving model ...\n",
      "506\n",
      "train_loss: 0.21720 valid_loss: 0.21935\n",
      "Validation loss decreased (0.219605 --> 0.219354).  Saving model ...\n",
      "507\n",
      "train_loss: 0.21601 valid_loss: 0.21914\n",
      "Validation loss decreased (0.219354 --> 0.219139).  Saving model ...\n",
      "508\n",
      "train_loss: 0.21606 valid_loss: 0.21914\n",
      "EarlyStopping counter: 1 out of 10\n",
      "509\n",
      "train_loss: 0.21538 valid_loss: 0.21884\n",
      "Validation loss decreased (0.219139 --> 0.218837).  Saving model ...\n",
      "510\n",
      "train_loss: 0.21562 valid_loss: 0.21853\n",
      "Validation loss decreased (0.218837 --> 0.218527).  Saving model ...\n",
      "511\n",
      "train_loss: 0.21487 valid_loss: 0.21833\n",
      "Validation loss decreased (0.218527 --> 0.218327).  Saving model ...\n",
      "512\n",
      "train_loss: 0.21504 valid_loss: 0.21821\n",
      "Validation loss decreased (0.218327 --> 0.218211).  Saving model ...\n",
      "513\n",
      "train_loss: 0.21510 valid_loss: 0.21802\n",
      "Validation loss decreased (0.218211 --> 0.218016).  Saving model ...\n",
      "514\n",
      "train_loss: 0.21425 valid_loss: 0.21774\n",
      "Validation loss decreased (0.218016 --> 0.217737).  Saving model ...\n",
      "515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.21524 valid_loss: 0.21748\n",
      "Validation loss decreased (0.217737 --> 0.217484).  Saving model ...\n",
      "516\n",
      "train_loss: 0.21466 valid_loss: 0.21737\n",
      "Validation loss decreased (0.217484 --> 0.217369).  Saving model ...\n",
      "517\n",
      "train_loss: 0.21427 valid_loss: 0.21706\n",
      "Validation loss decreased (0.217369 --> 0.217055).  Saving model ...\n",
      "518\n",
      "train_loss: 0.21414 valid_loss: 0.21680\n",
      "Validation loss decreased (0.217055 --> 0.216804).  Saving model ...\n",
      "519\n",
      "train_loss: 0.21375 valid_loss: 0.21667\n",
      "Validation loss decreased (0.216804 --> 0.216674).  Saving model ...\n",
      "520\n",
      "train_loss: 0.21321 valid_loss: 0.21632\n",
      "Validation loss decreased (0.216674 --> 0.216323).  Saving model ...\n",
      "521\n",
      "train_loss: 0.21313 valid_loss: 0.21633\n",
      "EarlyStopping counter: 1 out of 10\n",
      "522\n",
      "train_loss: 0.21307 valid_loss: 0.21582\n",
      "Validation loss decreased (0.216323 --> 0.215816).  Saving model ...\n",
      "523\n",
      "train_loss: 0.21294 valid_loss: 0.21591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "524\n",
      "train_loss: 0.21309 valid_loss: 0.21557\n",
      "Validation loss decreased (0.215816 --> 0.215573).  Saving model ...\n",
      "525\n",
      "train_loss: 0.21282 valid_loss: 0.21538\n",
      "Validation loss decreased (0.215573 --> 0.215375).  Saving model ...\n",
      "526\n",
      "train_loss: 0.21136 valid_loss: 0.21523\n",
      "Validation loss decreased (0.215375 --> 0.215233).  Saving model ...\n",
      "527\n",
      "train_loss: 0.21195 valid_loss: 0.21493\n",
      "Validation loss decreased (0.215233 --> 0.214930).  Saving model ...\n",
      "528\n",
      "train_loss: 0.21154 valid_loss: 0.21463\n",
      "Validation loss decreased (0.214930 --> 0.214626).  Saving model ...\n",
      "529\n",
      "train_loss: 0.21177 valid_loss: 0.21446\n",
      "Validation loss decreased (0.214626 --> 0.214455).  Saving model ...\n",
      "530\n",
      "train_loss: 0.21083 valid_loss: 0.21435\n",
      "Validation loss decreased (0.214455 --> 0.214353).  Saving model ...\n",
      "531\n",
      "train_loss: 0.21048 valid_loss: 0.21418\n",
      "Validation loss decreased (0.214353 --> 0.214182).  Saving model ...\n",
      "532\n",
      "train_loss: 0.21018 valid_loss: 0.21394\n",
      "Validation loss decreased (0.214182 --> 0.213936).  Saving model ...\n",
      "533\n",
      "train_loss: 0.21116 valid_loss: 0.21383\n",
      "Validation loss decreased (0.213936 --> 0.213834).  Saving model ...\n",
      "534\n",
      "train_loss: 0.20969 valid_loss: 0.21348\n",
      "Validation loss decreased (0.213834 --> 0.213484).  Saving model ...\n",
      "535\n",
      "train_loss: 0.21000 valid_loss: 0.21331\n",
      "Validation loss decreased (0.213484 --> 0.213314).  Saving model ...\n",
      "536\n",
      "train_loss: 0.21017 valid_loss: 0.21322\n",
      "Validation loss decreased (0.213314 --> 0.213219).  Saving model ...\n",
      "537\n",
      "train_loss: 0.20923 valid_loss: 0.21287\n",
      "Validation loss decreased (0.213219 --> 0.212874).  Saving model ...\n",
      "538\n",
      "train_loss: 0.20985 valid_loss: 0.21289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "539\n",
      "train_loss: 0.20857 valid_loss: 0.21260\n",
      "Validation loss decreased (0.212874 --> 0.212599).  Saving model ...\n",
      "540\n",
      "train_loss: 0.20853 valid_loss: 0.21245\n",
      "Validation loss decreased (0.212599 --> 0.212455).  Saving model ...\n",
      "541\n",
      "train_loss: 0.20774 valid_loss: 0.21218\n",
      "Validation loss decreased (0.212455 --> 0.212184).  Saving model ...\n",
      "542\n",
      "train_loss: 0.20876 valid_loss: 0.21186\n",
      "Validation loss decreased (0.212184 --> 0.211860).  Saving model ...\n",
      "543\n",
      "train_loss: 0.20790 valid_loss: 0.21179\n",
      "Validation loss decreased (0.211860 --> 0.211791).  Saving model ...\n",
      "544\n",
      "train_loss: 0.20815 valid_loss: 0.21159\n",
      "Validation loss decreased (0.211791 --> 0.211588).  Saving model ...\n",
      "545\n",
      "train_loss: 0.20755 valid_loss: 0.21140\n",
      "Validation loss decreased (0.211588 --> 0.211397).  Saving model ...\n",
      "546\n",
      "train_loss: 0.20821 valid_loss: 0.21124\n",
      "Validation loss decreased (0.211397 --> 0.211241).  Saving model ...\n",
      "547\n",
      "train_loss: 0.20762 valid_loss: 0.21088\n",
      "Validation loss decreased (0.211241 --> 0.210876).  Saving model ...\n",
      "548\n",
      "train_loss: 0.20706 valid_loss: 0.21098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "549\n",
      "train_loss: 0.20768 valid_loss: 0.21059\n",
      "Validation loss decreased (0.210876 --> 0.210593).  Saving model ...\n",
      "550\n",
      "train_loss: 0.20643 valid_loss: 0.21043\n",
      "Validation loss decreased (0.210593 --> 0.210431).  Saving model ...\n",
      "551\n",
      "train_loss: 0.20649 valid_loss: 0.21037\n",
      "Validation loss decreased (0.210431 --> 0.210371).  Saving model ...\n",
      "552\n",
      "train_loss: 0.20585 valid_loss: 0.20997\n",
      "Validation loss decreased (0.210371 --> 0.209974).  Saving model ...\n",
      "553\n",
      "train_loss: 0.20577 valid_loss: 0.20995\n",
      "Validation loss decreased (0.209974 --> 0.209955).  Saving model ...\n",
      "554\n",
      "train_loss: 0.20560 valid_loss: 0.20985\n",
      "Validation loss decreased (0.209955 --> 0.209849).  Saving model ...\n",
      "555\n",
      "train_loss: 0.20543 valid_loss: 0.20930\n",
      "Validation loss decreased (0.209849 --> 0.209302).  Saving model ...\n",
      "556\n",
      "train_loss: 0.20608 valid_loss: 0.20919\n",
      "Validation loss decreased (0.209302 --> 0.209186).  Saving model ...\n",
      "557\n",
      "train_loss: 0.20522 valid_loss: 0.20918\n",
      "Validation loss decreased (0.209186 --> 0.209183).  Saving model ...\n",
      "558\n",
      "train_loss: 0.20510 valid_loss: 0.20878\n",
      "Validation loss decreased (0.209183 --> 0.208783).  Saving model ...\n",
      "559\n",
      "train_loss: 0.20512 valid_loss: 0.20852\n",
      "Validation loss decreased (0.208783 --> 0.208522).  Saving model ...\n",
      "560\n",
      "train_loss: 0.20502 valid_loss: 0.20854\n",
      "EarlyStopping counter: 1 out of 10\n",
      "561\n",
      "train_loss: 0.20439 valid_loss: 0.20828\n",
      "Validation loss decreased (0.208522 --> 0.208279).  Saving model ...\n",
      "562\n",
      "train_loss: 0.20435 valid_loss: 0.20809\n",
      "Validation loss decreased (0.208279 --> 0.208094).  Saving model ...\n",
      "563\n",
      "train_loss: 0.20423 valid_loss: 0.20782\n",
      "Validation loss decreased (0.208094 --> 0.207820).  Saving model ...\n",
      "564\n",
      "train_loss: 0.20341 valid_loss: 0.20774\n",
      "Validation loss decreased (0.207820 --> 0.207737).  Saving model ...\n",
      "565\n",
      "train_loss: 0.20359 valid_loss: 0.20755\n",
      "Validation loss decreased (0.207737 --> 0.207553).  Saving model ...\n",
      "566\n",
      "train_loss: 0.20265 valid_loss: 0.20728\n",
      "Validation loss decreased (0.207553 --> 0.207284).  Saving model ...\n",
      "567\n",
      "train_loss: 0.20239 valid_loss: 0.20711\n",
      "Validation loss decreased (0.207284 --> 0.207112).  Saving model ...\n",
      "568\n",
      "train_loss: 0.20228 valid_loss: 0.20688\n",
      "Validation loss decreased (0.207112 --> 0.206877).  Saving model ...\n",
      "569\n",
      "train_loss: 0.20289 valid_loss: 0.20672\n",
      "Validation loss decreased (0.206877 --> 0.206717).  Saving model ...\n",
      "570\n",
      "train_loss: 0.20242 valid_loss: 0.20659\n",
      "Validation loss decreased (0.206717 --> 0.206588).  Saving model ...\n",
      "571\n",
      "train_loss: 0.20178 valid_loss: 0.20629\n",
      "Validation loss decreased (0.206588 --> 0.206289).  Saving model ...\n",
      "572\n",
      "train_loss: 0.20179 valid_loss: 0.20628\n",
      "Validation loss decreased (0.206289 --> 0.206284).  Saving model ...\n",
      "573\n",
      "train_loss: 0.20163 valid_loss: 0.20598\n",
      "Validation loss decreased (0.206284 --> 0.205981).  Saving model ...\n",
      "574\n",
      "train_loss: 0.20178 valid_loss: 0.20573\n",
      "Validation loss decreased (0.205981 --> 0.205733).  Saving model ...\n",
      "575\n",
      "train_loss: 0.20096 valid_loss: 0.20550\n",
      "Validation loss decreased (0.205733 --> 0.205499).  Saving model ...\n",
      "576\n",
      "train_loss: 0.20133 valid_loss: 0.20532\n",
      "Validation loss decreased (0.205499 --> 0.205322).  Saving model ...\n",
      "577\n",
      "train_loss: 0.20090 valid_loss: 0.20520\n",
      "Validation loss decreased (0.205322 --> 0.205201).  Saving model ...\n",
      "578\n",
      "train_loss: 0.20078 valid_loss: 0.20490\n",
      "Validation loss decreased (0.205201 --> 0.204904).  Saving model ...\n",
      "579\n",
      "train_loss: 0.20021 valid_loss: 0.20470\n",
      "Validation loss decreased (0.204904 --> 0.204703).  Saving model ...\n",
      "580\n",
      "train_loss: 0.20044 valid_loss: 0.20477\n",
      "EarlyStopping counter: 1 out of 10\n",
      "581\n",
      "train_loss: 0.19942 valid_loss: 0.20437\n",
      "Validation loss decreased (0.204703 --> 0.204369).  Saving model ...\n",
      "582\n",
      "train_loss: 0.20067 valid_loss: 0.20430\n",
      "Validation loss decreased (0.204369 --> 0.204295).  Saving model ...\n",
      "583\n",
      "train_loss: 0.19958 valid_loss: 0.20406\n",
      "Validation loss decreased (0.204295 --> 0.204060).  Saving model ...\n",
      "584\n",
      "train_loss: 0.19936 valid_loss: 0.20393\n",
      "Validation loss decreased (0.204060 --> 0.203934).  Saving model ...\n",
      "585\n",
      "train_loss: 0.19960 valid_loss: 0.20380\n",
      "Validation loss decreased (0.203934 --> 0.203795).  Saving model ...\n",
      "586\n",
      "train_loss: 0.19854 valid_loss: 0.20346\n",
      "Validation loss decreased (0.203795 --> 0.203458).  Saving model ...\n",
      "587\n",
      "train_loss: 0.19971 valid_loss: 0.20338\n",
      "Validation loss decreased (0.203458 --> 0.203375).  Saving model ...\n",
      "588\n",
      "train_loss: 0.19830 valid_loss: 0.20317\n",
      "Validation loss decreased (0.203375 --> 0.203172).  Saving model ...\n",
      "589\n",
      "train_loss: 0.19913 valid_loss: 0.20301\n",
      "Validation loss decreased (0.203172 --> 0.203012).  Saving model ...\n",
      "590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.19842 valid_loss: 0.20284\n",
      "Validation loss decreased (0.203012 --> 0.202841).  Saving model ...\n",
      "591\n",
      "train_loss: 0.19787 valid_loss: 0.20264\n",
      "Validation loss decreased (0.202841 --> 0.202640).  Saving model ...\n",
      "592\n",
      "train_loss: 0.19760 valid_loss: 0.20250\n",
      "Validation loss decreased (0.202640 --> 0.202505).  Saving model ...\n",
      "593\n",
      "train_loss: 0.19662 valid_loss: 0.20232\n",
      "Validation loss decreased (0.202505 --> 0.202321).  Saving model ...\n",
      "594\n",
      "train_loss: 0.19658 valid_loss: 0.20200\n",
      "Validation loss decreased (0.202321 --> 0.202001).  Saving model ...\n",
      "595\n",
      "train_loss: 0.19665 valid_loss: 0.20184\n",
      "Validation loss decreased (0.202001 --> 0.201837).  Saving model ...\n",
      "596\n",
      "train_loss: 0.19701 valid_loss: 0.20177\n",
      "Validation loss decreased (0.201837 --> 0.201774).  Saving model ...\n",
      "597\n",
      "train_loss: 0.19619 valid_loss: 0.20159\n",
      "Validation loss decreased (0.201774 --> 0.201592).  Saving model ...\n",
      "598\n",
      "train_loss: 0.19593 valid_loss: 0.20136\n",
      "Validation loss decreased (0.201592 --> 0.201360).  Saving model ...\n",
      "599\n",
      "train_loss: 0.19623 valid_loss: 0.20115\n",
      "Validation loss decreased (0.201360 --> 0.201151).  Saving model ...\n",
      "600\n",
      "train_loss: 0.19608 valid_loss: 0.20095\n",
      "Validation loss decreased (0.201151 --> 0.200953).  Saving model ...\n",
      "601\n",
      "train_loss: 0.19535 valid_loss: 0.20082\n",
      "Validation loss decreased (0.200953 --> 0.200816).  Saving model ...\n",
      "602\n",
      "train_loss: 0.19601 valid_loss: 0.20056\n",
      "Validation loss decreased (0.200816 --> 0.200557).  Saving model ...\n",
      "603\n",
      "train_loss: 0.19653 valid_loss: 0.20033\n",
      "Validation loss decreased (0.200557 --> 0.200326).  Saving model ...\n",
      "604\n",
      "train_loss: 0.19570 valid_loss: 0.20017\n",
      "Validation loss decreased (0.200326 --> 0.200175).  Saving model ...\n",
      "605\n",
      "train_loss: 0.19494 valid_loss: 0.20015\n",
      "Validation loss decreased (0.200175 --> 0.200152).  Saving model ...\n",
      "606\n",
      "train_loss: 0.19473 valid_loss: 0.20000\n",
      "Validation loss decreased (0.200152 --> 0.200003).  Saving model ...\n",
      "607\n",
      "train_loss: 0.19452 valid_loss: 0.19978\n",
      "Validation loss decreased (0.200003 --> 0.199784).  Saving model ...\n",
      "608\n",
      "train_loss: 0.19503 valid_loss: 0.19956\n",
      "Validation loss decreased (0.199784 --> 0.199562).  Saving model ...\n",
      "609\n",
      "train_loss: 0.19431 valid_loss: 0.19953\n",
      "Validation loss decreased (0.199562 --> 0.199534).  Saving model ...\n",
      "610\n",
      "train_loss: 0.19364 valid_loss: 0.19900\n",
      "Validation loss decreased (0.199534 --> 0.198999).  Saving model ...\n",
      "611\n",
      "train_loss: 0.19433 valid_loss: 0.19892\n",
      "Validation loss decreased (0.198999 --> 0.198921).  Saving model ...\n",
      "612\n",
      "train_loss: 0.19275 valid_loss: 0.19871\n",
      "Validation loss decreased (0.198921 --> 0.198714).  Saving model ...\n",
      "613\n",
      "train_loss: 0.19270 valid_loss: 0.19851\n",
      "Validation loss decreased (0.198714 --> 0.198514).  Saving model ...\n",
      "614\n",
      "train_loss: 0.19369 valid_loss: 0.19844\n",
      "Validation loss decreased (0.198514 --> 0.198441).  Saving model ...\n",
      "615\n",
      "train_loss: 0.19277 valid_loss: 0.19833\n",
      "Validation loss decreased (0.198441 --> 0.198333).  Saving model ...\n",
      "616\n",
      "train_loss: 0.19250 valid_loss: 0.19816\n",
      "Validation loss decreased (0.198333 --> 0.198160).  Saving model ...\n",
      "617\n",
      "train_loss: 0.19317 valid_loss: 0.19817\n",
      "EarlyStopping counter: 1 out of 10\n",
      "618\n",
      "train_loss: 0.19171 valid_loss: 0.19782\n",
      "Validation loss decreased (0.198160 --> 0.197815).  Saving model ...\n",
      "619\n",
      "train_loss: 0.19234 valid_loss: 0.19761\n",
      "Validation loss decreased (0.197815 --> 0.197612).  Saving model ...\n",
      "620\n",
      "train_loss: 0.19145 valid_loss: 0.19738\n",
      "Validation loss decreased (0.197612 --> 0.197381).  Saving model ...\n",
      "621\n",
      "train_loss: 0.19188 valid_loss: 0.19719\n",
      "Validation loss decreased (0.197381 --> 0.197190).  Saving model ...\n",
      "622\n",
      "train_loss: 0.19126 valid_loss: 0.19719\n",
      "Validation loss decreased (0.197190 --> 0.197188).  Saving model ...\n",
      "623\n",
      "train_loss: 0.19196 valid_loss: 0.19703\n",
      "Validation loss decreased (0.197188 --> 0.197029).  Saving model ...\n",
      "624\n",
      "train_loss: 0.19227 valid_loss: 0.19673\n",
      "Validation loss decreased (0.197029 --> 0.196732).  Saving model ...\n",
      "625\n",
      "train_loss: 0.19126 valid_loss: 0.19661\n",
      "Validation loss decreased (0.196732 --> 0.196613).  Saving model ...\n",
      "626\n",
      "train_loss: 0.19050 valid_loss: 0.19636\n",
      "Validation loss decreased (0.196613 --> 0.196356).  Saving model ...\n",
      "627\n",
      "train_loss: 0.19131 valid_loss: 0.19622\n",
      "Validation loss decreased (0.196356 --> 0.196215).  Saving model ...\n",
      "628\n",
      "train_loss: 0.19034 valid_loss: 0.19598\n",
      "Validation loss decreased (0.196215 --> 0.195983).  Saving model ...\n",
      "629\n",
      "train_loss: 0.19089 valid_loss: 0.19586\n",
      "Validation loss decreased (0.195983 --> 0.195861).  Saving model ...\n",
      "630\n",
      "train_loss: 0.19010 valid_loss: 0.19562\n",
      "Validation loss decreased (0.195861 --> 0.195624).  Saving model ...\n",
      "631\n",
      "train_loss: 0.18994 valid_loss: 0.19543\n",
      "Validation loss decreased (0.195624 --> 0.195433).  Saving model ...\n",
      "632\n",
      "train_loss: 0.18978 valid_loss: 0.19551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "633\n",
      "train_loss: 0.18956 valid_loss: 0.19526\n",
      "Validation loss decreased (0.195433 --> 0.195257).  Saving model ...\n",
      "634\n",
      "train_loss: 0.18900 valid_loss: 0.19513\n",
      "Validation loss decreased (0.195257 --> 0.195128).  Saving model ...\n",
      "635\n",
      "train_loss: 0.18964 valid_loss: 0.19468\n",
      "Validation loss decreased (0.195128 --> 0.194677).  Saving model ...\n",
      "636\n",
      "train_loss: 0.18881 valid_loss: 0.19485\n",
      "EarlyStopping counter: 1 out of 10\n",
      "637\n",
      "train_loss: 0.18842 valid_loss: 0.19453\n",
      "Validation loss decreased (0.194677 --> 0.194527).  Saving model ...\n",
      "638\n",
      "train_loss: 0.18926 valid_loss: 0.19435\n",
      "Validation loss decreased (0.194527 --> 0.194355).  Saving model ...\n",
      "639\n",
      "train_loss: 0.18794 valid_loss: 0.19437\n",
      "EarlyStopping counter: 1 out of 10\n",
      "640\n",
      "train_loss: 0.18796 valid_loss: 0.19413\n",
      "Validation loss decreased (0.194355 --> 0.194127).  Saving model ...\n",
      "641\n",
      "train_loss: 0.18775 valid_loss: 0.19400\n",
      "Validation loss decreased (0.194127 --> 0.193997).  Saving model ...\n",
      "642\n",
      "train_loss: 0.18837 valid_loss: 0.19366\n",
      "Validation loss decreased (0.193997 --> 0.193656).  Saving model ...\n",
      "643\n",
      "train_loss: 0.18745 valid_loss: 0.19357\n",
      "Validation loss decreased (0.193656 --> 0.193569).  Saving model ...\n",
      "644\n",
      "train_loss: 0.18792 valid_loss: 0.19357\n",
      "EarlyStopping counter: 1 out of 10\n",
      "645\n",
      "train_loss: 0.18684 valid_loss: 0.19317\n",
      "Validation loss decreased (0.193569 --> 0.193171).  Saving model ...\n",
      "646\n",
      "train_loss: 0.18632 valid_loss: 0.19293\n",
      "Validation loss decreased (0.193171 --> 0.192934).  Saving model ...\n",
      "647\n",
      "train_loss: 0.18669 valid_loss: 0.19298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "648\n",
      "train_loss: 0.18607 valid_loss: 0.19276\n",
      "Validation loss decreased (0.192934 --> 0.192759).  Saving model ...\n",
      "649\n",
      "train_loss: 0.18683 valid_loss: 0.19257\n",
      "Validation loss decreased (0.192759 --> 0.192574).  Saving model ...\n",
      "650\n",
      "train_loss: 0.18568 valid_loss: 0.19254\n",
      "Validation loss decreased (0.192574 --> 0.192544).  Saving model ...\n",
      "651\n",
      "train_loss: 0.18556 valid_loss: 0.19217\n",
      "Validation loss decreased (0.192544 --> 0.192171).  Saving model ...\n",
      "652\n",
      "train_loss: 0.18602 valid_loss: 0.19208\n",
      "Validation loss decreased (0.192171 --> 0.192081).  Saving model ...\n",
      "653\n",
      "train_loss: 0.18568 valid_loss: 0.19185\n",
      "Validation loss decreased (0.192081 --> 0.191848).  Saving model ...\n",
      "654\n",
      "train_loss: 0.18587 valid_loss: 0.19182\n",
      "Validation loss decreased (0.191848 --> 0.191815).  Saving model ...\n",
      "655\n",
      "train_loss: 0.18551 valid_loss: 0.19143\n",
      "Validation loss decreased (0.191815 --> 0.191426).  Saving model ...\n",
      "656\n",
      "train_loss: 0.18496 valid_loss: 0.19155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "657\n",
      "train_loss: 0.18522 valid_loss: 0.19127\n",
      "Validation loss decreased (0.191426 --> 0.191268).  Saving model ...\n",
      "658\n",
      "train_loss: 0.18535 valid_loss: 0.19113\n",
      "Validation loss decreased (0.191268 --> 0.191127).  Saving model ...\n",
      "659\n",
      "train_loss: 0.18402 valid_loss: 0.19090\n",
      "Validation loss decreased (0.191127 --> 0.190900).  Saving model ...\n",
      "660\n",
      "train_loss: 0.18441 valid_loss: 0.19064\n",
      "Validation loss decreased (0.190900 --> 0.190644).  Saving model ...\n",
      "661\n",
      "train_loss: 0.18456 valid_loss: 0.19078\n",
      "EarlyStopping counter: 1 out of 10\n",
      "662\n",
      "train_loss: 0.18405 valid_loss: 0.19047\n",
      "Validation loss decreased (0.190644 --> 0.190467).  Saving model ...\n",
      "663\n",
      "train_loss: 0.18525 valid_loss: 0.19049\n",
      "EarlyStopping counter: 1 out of 10\n",
      "664\n",
      "train_loss: 0.18387 valid_loss: 0.19010\n",
      "Validation loss decreased (0.190467 --> 0.190103).  Saving model ...\n",
      "665\n",
      "train_loss: 0.18394 valid_loss: 0.19003\n",
      "Validation loss decreased (0.190103 --> 0.190029).  Saving model ...\n",
      "666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.18344 valid_loss: 0.18976\n",
      "Validation loss decreased (0.190029 --> 0.189760).  Saving model ...\n",
      "667\n",
      "train_loss: 0.18259 valid_loss: 0.18969\n",
      "Validation loss decreased (0.189760 --> 0.189688).  Saving model ...\n",
      "668\n",
      "train_loss: 0.18319 valid_loss: 0.18948\n",
      "Validation loss decreased (0.189688 --> 0.189476).  Saving model ...\n",
      "669\n",
      "train_loss: 0.18247 valid_loss: 0.18933\n",
      "Validation loss decreased (0.189476 --> 0.189331).  Saving model ...\n",
      "670\n",
      "train_loss: 0.18213 valid_loss: 0.18906\n",
      "Validation loss decreased (0.189331 --> 0.189061).  Saving model ...\n",
      "671\n",
      "train_loss: 0.18293 valid_loss: 0.18889\n",
      "Validation loss decreased (0.189061 --> 0.188891).  Saving model ...\n",
      "672\n",
      "train_loss: 0.18199 valid_loss: 0.18877\n",
      "Validation loss decreased (0.188891 --> 0.188765).  Saving model ...\n",
      "673\n",
      "train_loss: 0.18263 valid_loss: 0.18877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "674\n",
      "train_loss: 0.18172 valid_loss: 0.18865\n",
      "Validation loss decreased (0.188765 --> 0.188655).  Saving model ...\n",
      "675\n",
      "train_loss: 0.18161 valid_loss: 0.18856\n",
      "Validation loss decreased (0.188655 --> 0.188564).  Saving model ...\n",
      "676\n",
      "train_loss: 0.18118 valid_loss: 0.18822\n",
      "Validation loss decreased (0.188564 --> 0.188216).  Saving model ...\n",
      "677\n",
      "train_loss: 0.18131 valid_loss: 0.18811\n",
      "Validation loss decreased (0.188216 --> 0.188110).  Saving model ...\n",
      "678\n",
      "train_loss: 0.18194 valid_loss: 0.18804\n",
      "Validation loss decreased (0.188110 --> 0.188036).  Saving model ...\n",
      "679\n",
      "train_loss: 0.18038 valid_loss: 0.18777\n",
      "Validation loss decreased (0.188036 --> 0.187767).  Saving model ...\n",
      "680\n",
      "train_loss: 0.18037 valid_loss: 0.18765\n",
      "Validation loss decreased (0.187767 --> 0.187655).  Saving model ...\n",
      "681\n",
      "train_loss: 0.18049 valid_loss: 0.18740\n",
      "Validation loss decreased (0.187655 --> 0.187403).  Saving model ...\n",
      "682\n",
      "train_loss: 0.18056 valid_loss: 0.18720\n",
      "Validation loss decreased (0.187403 --> 0.187202).  Saving model ...\n",
      "683\n",
      "train_loss: 0.18023 valid_loss: 0.18720\n",
      "Validation loss decreased (0.187202 --> 0.187196).  Saving model ...\n",
      "684\n",
      "train_loss: 0.17944 valid_loss: 0.18699\n",
      "Validation loss decreased (0.187196 --> 0.186987).  Saving model ...\n",
      "685\n",
      "train_loss: 0.17994 valid_loss: 0.18675\n",
      "Validation loss decreased (0.186987 --> 0.186746).  Saving model ...\n",
      "686\n",
      "train_loss: 0.17936 valid_loss: 0.18675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "687\n",
      "train_loss: 0.18025 valid_loss: 0.18665\n",
      "Validation loss decreased (0.186746 --> 0.186650).  Saving model ...\n",
      "688\n",
      "train_loss: 0.17902 valid_loss: 0.18645\n",
      "Validation loss decreased (0.186650 --> 0.186455).  Saving model ...\n",
      "689\n",
      "train_loss: 0.17983 valid_loss: 0.18624\n",
      "Validation loss decreased (0.186455 --> 0.186240).  Saving model ...\n",
      "690\n",
      "train_loss: 0.17844 valid_loss: 0.18607\n",
      "Validation loss decreased (0.186240 --> 0.186072).  Saving model ...\n",
      "691\n",
      "train_loss: 0.17827 valid_loss: 0.18595\n",
      "Validation loss decreased (0.186072 --> 0.185953).  Saving model ...\n",
      "692\n",
      "train_loss: 0.17860 valid_loss: 0.18580\n",
      "Validation loss decreased (0.185953 --> 0.185804).  Saving model ...\n",
      "693\n",
      "train_loss: 0.17829 valid_loss: 0.18575\n",
      "Validation loss decreased (0.185804 --> 0.185747).  Saving model ...\n",
      "694\n",
      "train_loss: 0.17833 valid_loss: 0.18557\n",
      "Validation loss decreased (0.185747 --> 0.185574).  Saving model ...\n",
      "695\n",
      "train_loss: 0.17824 valid_loss: 0.18531\n",
      "Validation loss decreased (0.185574 --> 0.185309).  Saving model ...\n",
      "696\n",
      "train_loss: 0.17766 valid_loss: 0.18528\n",
      "Validation loss decreased (0.185309 --> 0.185285).  Saving model ...\n",
      "697\n",
      "train_loss: 0.17806 valid_loss: 0.18517\n",
      "Validation loss decreased (0.185285 --> 0.185173).  Saving model ...\n",
      "698\n",
      "train_loss: 0.17730 valid_loss: 0.18501\n",
      "Validation loss decreased (0.185173 --> 0.185009).  Saving model ...\n",
      "699\n",
      "train_loss: 0.17735 valid_loss: 0.18467\n",
      "Validation loss decreased (0.185009 --> 0.184668).  Saving model ...\n",
      "700\n",
      "train_loss: 0.17773 valid_loss: 0.18448\n",
      "Validation loss decreased (0.184668 --> 0.184482).  Saving model ...\n",
      "701\n",
      "train_loss: 0.17705 valid_loss: 0.18453\n",
      "EarlyStopping counter: 1 out of 10\n",
      "702\n",
      "train_loss: 0.17670 valid_loss: 0.18426\n",
      "Validation loss decreased (0.184482 --> 0.184265).  Saving model ...\n",
      "703\n",
      "train_loss: 0.17673 valid_loss: 0.18410\n",
      "Validation loss decreased (0.184265 --> 0.184105).  Saving model ...\n",
      "704\n",
      "train_loss: 0.17667 valid_loss: 0.18401\n",
      "Validation loss decreased (0.184105 --> 0.184014).  Saving model ...\n",
      "705\n",
      "train_loss: 0.17659 valid_loss: 0.18395\n",
      "Validation loss decreased (0.184014 --> 0.183945).  Saving model ...\n",
      "706\n",
      "train_loss: 0.17671 valid_loss: 0.18375\n",
      "Validation loss decreased (0.183945 --> 0.183753).  Saving model ...\n",
      "707\n",
      "train_loss: 0.17597 valid_loss: 0.18357\n",
      "Validation loss decreased (0.183753 --> 0.183572).  Saving model ...\n",
      "708\n",
      "train_loss: 0.17588 valid_loss: 0.18333\n",
      "Validation loss decreased (0.183572 --> 0.183331).  Saving model ...\n",
      "709\n",
      "train_loss: 0.17567 valid_loss: 0.18323\n",
      "Validation loss decreased (0.183331 --> 0.183234).  Saving model ...\n",
      "710\n",
      "train_loss: 0.17529 valid_loss: 0.18307\n",
      "Validation loss decreased (0.183234 --> 0.183070).  Saving model ...\n",
      "711\n",
      "train_loss: 0.17566 valid_loss: 0.18285\n",
      "Validation loss decreased (0.183070 --> 0.182854).  Saving model ...\n",
      "712\n",
      "train_loss: 0.17521 valid_loss: 0.18295\n",
      "EarlyStopping counter: 1 out of 10\n",
      "713\n",
      "train_loss: 0.17484 valid_loss: 0.18255\n",
      "Validation loss decreased (0.182854 --> 0.182548).  Saving model ...\n",
      "714\n",
      "train_loss: 0.17510 valid_loss: 0.18258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "715\n",
      "train_loss: 0.17617 valid_loss: 0.18233\n",
      "Validation loss decreased (0.182548 --> 0.182330).  Saving model ...\n",
      "716\n",
      "train_loss: 0.17455 valid_loss: 0.18218\n",
      "Validation loss decreased (0.182330 --> 0.182178).  Saving model ...\n",
      "717\n",
      "train_loss: 0.17387 valid_loss: 0.18196\n",
      "Validation loss decreased (0.182178 --> 0.181958).  Saving model ...\n",
      "718\n",
      "train_loss: 0.17540 valid_loss: 0.18186\n",
      "Validation loss decreased (0.181958 --> 0.181856).  Saving model ...\n",
      "719\n",
      "train_loss: 0.17412 valid_loss: 0.18179\n",
      "Validation loss decreased (0.181856 --> 0.181789).  Saving model ...\n",
      "720\n",
      "train_loss: 0.17381 valid_loss: 0.18163\n",
      "Validation loss decreased (0.181789 --> 0.181625).  Saving model ...\n",
      "721\n",
      "train_loss: 0.17391 valid_loss: 0.18147\n",
      "Validation loss decreased (0.181625 --> 0.181468).  Saving model ...\n",
      "722\n",
      "train_loss: 0.17326 valid_loss: 0.18137\n",
      "Validation loss decreased (0.181468 --> 0.181372).  Saving model ...\n",
      "723\n",
      "train_loss: 0.17371 valid_loss: 0.18114\n",
      "Validation loss decreased (0.181372 --> 0.181142).  Saving model ...\n",
      "724\n",
      "train_loss: 0.17285 valid_loss: 0.18095\n",
      "Validation loss decreased (0.181142 --> 0.180954).  Saving model ...\n",
      "725\n",
      "train_loss: 0.17245 valid_loss: 0.18087\n",
      "Validation loss decreased (0.180954 --> 0.180869).  Saving model ...\n",
      "726\n",
      "train_loss: 0.17234 valid_loss: 0.18086\n",
      "Validation loss decreased (0.180869 --> 0.180858).  Saving model ...\n",
      "727\n",
      "train_loss: 0.17260 valid_loss: 0.18065\n",
      "Validation loss decreased (0.180858 --> 0.180646).  Saving model ...\n",
      "728\n",
      "train_loss: 0.17283 valid_loss: 0.18037\n",
      "Validation loss decreased (0.180646 --> 0.180371).  Saving model ...\n",
      "729\n",
      "train_loss: 0.17279 valid_loss: 0.18027\n",
      "Validation loss decreased (0.180371 --> 0.180272).  Saving model ...\n",
      "730\n",
      "train_loss: 0.17166 valid_loss: 0.18023\n",
      "Validation loss decreased (0.180272 --> 0.180225).  Saving model ...\n",
      "731\n",
      "train_loss: 0.17230 valid_loss: 0.18001\n",
      "Validation loss decreased (0.180225 --> 0.180012).  Saving model ...\n",
      "732\n",
      "train_loss: 0.17150 valid_loss: 0.17991\n",
      "Validation loss decreased (0.180012 --> 0.179914).  Saving model ...\n",
      "733\n",
      "train_loss: 0.17236 valid_loss: 0.17974\n",
      "Validation loss decreased (0.179914 --> 0.179744).  Saving model ...\n",
      "734\n",
      "train_loss: 0.17162 valid_loss: 0.17962\n",
      "Validation loss decreased (0.179744 --> 0.179620).  Saving model ...\n",
      "735\n",
      "train_loss: 0.17139 valid_loss: 0.17945\n",
      "Validation loss decreased (0.179620 --> 0.179447).  Saving model ...\n",
      "736\n",
      "train_loss: 0.17138 valid_loss: 0.17930\n",
      "Validation loss decreased (0.179447 --> 0.179301).  Saving model ...\n",
      "737\n",
      "train_loss: 0.17114 valid_loss: 0.17928\n",
      "Validation loss decreased (0.179301 --> 0.179283).  Saving model ...\n",
      "738\n",
      "train_loss: 0.17088 valid_loss: 0.17890\n",
      "Validation loss decreased (0.179283 --> 0.178905).  Saving model ...\n",
      "739\n",
      "train_loss: 0.17043 valid_loss: 0.17894\n",
      "EarlyStopping counter: 1 out of 10\n",
      "740\n",
      "train_loss: 0.17037 valid_loss: 0.17877\n",
      "Validation loss decreased (0.178905 --> 0.178767).  Saving model ...\n",
      "741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.17046 valid_loss: 0.17876\n",
      "Validation loss decreased (0.178767 --> 0.178756).  Saving model ...\n",
      "742\n",
      "train_loss: 0.17027 valid_loss: 0.17845\n",
      "Validation loss decreased (0.178756 --> 0.178450).  Saving model ...\n",
      "743\n",
      "train_loss: 0.17019 valid_loss: 0.17835\n",
      "Validation loss decreased (0.178450 --> 0.178353).  Saving model ...\n",
      "744\n",
      "train_loss: 0.16960 valid_loss: 0.17816\n",
      "Validation loss decreased (0.178353 --> 0.178159).  Saving model ...\n",
      "745\n",
      "train_loss: 0.17166 valid_loss: 0.17813\n",
      "Validation loss decreased (0.178159 --> 0.178133).  Saving model ...\n",
      "746\n",
      "train_loss: 0.16931 valid_loss: 0.17796\n",
      "Validation loss decreased (0.178133 --> 0.177957).  Saving model ...\n",
      "747\n",
      "train_loss: 0.16903 valid_loss: 0.17778\n",
      "Validation loss decreased (0.177957 --> 0.177778).  Saving model ...\n",
      "748\n",
      "train_loss: 0.16892 valid_loss: 0.17775\n",
      "Validation loss decreased (0.177778 --> 0.177748).  Saving model ...\n",
      "749\n",
      "train_loss: 0.16907 valid_loss: 0.17762\n",
      "Validation loss decreased (0.177748 --> 0.177617).  Saving model ...\n",
      "750\n",
      "train_loss: 0.16896 valid_loss: 0.17736\n",
      "Validation loss decreased (0.177617 --> 0.177362).  Saving model ...\n",
      "751\n",
      "train_loss: 0.16919 valid_loss: 0.17739\n",
      "EarlyStopping counter: 1 out of 10\n",
      "752\n",
      "train_loss: 0.16932 valid_loss: 0.17714\n",
      "Validation loss decreased (0.177362 --> 0.177141).  Saving model ...\n",
      "753\n",
      "train_loss: 0.16927 valid_loss: 0.17702\n",
      "Validation loss decreased (0.177141 --> 0.177016).  Saving model ...\n",
      "754\n",
      "train_loss: 0.16829 valid_loss: 0.17682\n",
      "Validation loss decreased (0.177016 --> 0.176819).  Saving model ...\n",
      "755\n",
      "train_loss: 0.16769 valid_loss: 0.17664\n",
      "Validation loss decreased (0.176819 --> 0.176643).  Saving model ...\n",
      "756\n",
      "train_loss: 0.16787 valid_loss: 0.17654\n",
      "Validation loss decreased (0.176643 --> 0.176538).  Saving model ...\n",
      "757\n",
      "train_loss: 0.16840 valid_loss: 0.17644\n",
      "Validation loss decreased (0.176538 --> 0.176443).  Saving model ...\n",
      "758\n",
      "train_loss: 0.16757 valid_loss: 0.17628\n",
      "Validation loss decreased (0.176443 --> 0.176280).  Saving model ...\n",
      "759\n",
      "train_loss: 0.16757 valid_loss: 0.17622\n",
      "Validation loss decreased (0.176280 --> 0.176223).  Saving model ...\n",
      "760\n",
      "train_loss: 0.16738 valid_loss: 0.17616\n",
      "Validation loss decreased (0.176223 --> 0.176159).  Saving model ...\n",
      "761\n",
      "train_loss: 0.16781 valid_loss: 0.17609\n",
      "Validation loss decreased (0.176159 --> 0.176086).  Saving model ...\n",
      "762\n",
      "train_loss: 0.16653 valid_loss: 0.17571\n",
      "Validation loss decreased (0.176086 --> 0.175711).  Saving model ...\n",
      "763\n",
      "train_loss: 0.16846 valid_loss: 0.17570\n",
      "Validation loss decreased (0.175711 --> 0.175697).  Saving model ...\n",
      "764\n",
      "train_loss: 0.16665 valid_loss: 0.17551\n",
      "Validation loss decreased (0.175697 --> 0.175513).  Saving model ...\n",
      "765\n",
      "train_loss: 0.16676 valid_loss: 0.17536\n",
      "Validation loss decreased (0.175513 --> 0.175356).  Saving model ...\n",
      "766\n",
      "train_loss: 0.16643 valid_loss: 0.17512\n",
      "Validation loss decreased (0.175356 --> 0.175116).  Saving model ...\n",
      "767\n",
      "train_loss: 0.16632 valid_loss: 0.17510\n",
      "Validation loss decreased (0.175116 --> 0.175098).  Saving model ...\n",
      "768\n",
      "train_loss: 0.16708 valid_loss: 0.17522\n",
      "EarlyStopping counter: 1 out of 10\n",
      "769\n",
      "train_loss: 0.16589 valid_loss: 0.17509\n",
      "Validation loss decreased (0.175098 --> 0.175092).  Saving model ...\n",
      "770\n",
      "train_loss: 0.16565 valid_loss: 0.17463\n",
      "Validation loss decreased (0.175092 --> 0.174630).  Saving model ...\n",
      "771\n",
      "train_loss: 0.16570 valid_loss: 0.17473\n",
      "EarlyStopping counter: 1 out of 10\n",
      "772\n",
      "train_loss: 0.16570 valid_loss: 0.17453\n",
      "Validation loss decreased (0.174630 --> 0.174526).  Saving model ...\n",
      "773\n",
      "train_loss: 0.16500 valid_loss: 0.17433\n",
      "Validation loss decreased (0.174526 --> 0.174331).  Saving model ...\n",
      "774\n",
      "train_loss: 0.16557 valid_loss: 0.17423\n",
      "Validation loss decreased (0.174331 --> 0.174227).  Saving model ...\n",
      "775\n",
      "train_loss: 0.16523 valid_loss: 0.17422\n",
      "Validation loss decreased (0.174227 --> 0.174216).  Saving model ...\n",
      "776\n",
      "train_loss: 0.16480 valid_loss: 0.17396\n",
      "Validation loss decreased (0.174216 --> 0.173961).  Saving model ...\n",
      "777\n",
      "train_loss: 0.16428 valid_loss: 0.17388\n",
      "Validation loss decreased (0.173961 --> 0.173883).  Saving model ...\n",
      "778\n",
      "train_loss: 0.16489 valid_loss: 0.17372\n",
      "Validation loss decreased (0.173883 --> 0.173716).  Saving model ...\n",
      "779\n",
      "train_loss: 0.16497 valid_loss: 0.17354\n",
      "Validation loss decreased (0.173716 --> 0.173537).  Saving model ...\n",
      "780\n",
      "train_loss: 0.16451 valid_loss: 0.17331\n",
      "Validation loss decreased (0.173537 --> 0.173308).  Saving model ...\n",
      "781\n",
      "train_loss: 0.16472 valid_loss: 0.17338\n",
      "EarlyStopping counter: 1 out of 10\n",
      "782\n",
      "train_loss: 0.16371 valid_loss: 0.17317\n",
      "Validation loss decreased (0.173308 --> 0.173175).  Saving model ...\n",
      "783\n",
      "train_loss: 0.16440 valid_loss: 0.17315\n",
      "Validation loss decreased (0.173175 --> 0.173148).  Saving model ...\n",
      "784\n",
      "train_loss: 0.16363 valid_loss: 0.17289\n",
      "Validation loss decreased (0.173148 --> 0.172886).  Saving model ...\n",
      "785\n",
      "train_loss: 0.16318 valid_loss: 0.17276\n",
      "Validation loss decreased (0.172886 --> 0.172763).  Saving model ...\n",
      "786\n",
      "train_loss: 0.16386 valid_loss: 0.17268\n",
      "Validation loss decreased (0.172763 --> 0.172683).  Saving model ...\n",
      "787\n",
      "train_loss: 0.16335 valid_loss: 0.17244\n",
      "Validation loss decreased (0.172683 --> 0.172442).  Saving model ...\n",
      "788\n",
      "train_loss: 0.16378 valid_loss: 0.17226\n",
      "Validation loss decreased (0.172442 --> 0.172259).  Saving model ...\n",
      "789\n",
      "train_loss: 0.16272 valid_loss: 0.17236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "790\n",
      "train_loss: 0.16229 valid_loss: 0.17214\n",
      "Validation loss decreased (0.172259 --> 0.172142).  Saving model ...\n",
      "791\n",
      "train_loss: 0.16250 valid_loss: 0.17215\n",
      "EarlyStopping counter: 1 out of 10\n",
      "792\n",
      "train_loss: 0.16278 valid_loss: 0.17191\n",
      "Validation loss decreased (0.172142 --> 0.171913).  Saving model ...\n",
      "793\n",
      "train_loss: 0.16225 valid_loss: 0.17172\n",
      "Validation loss decreased (0.171913 --> 0.171716).  Saving model ...\n",
      "794\n",
      "train_loss: 0.16369 valid_loss: 0.17174\n",
      "EarlyStopping counter: 1 out of 10\n",
      "795\n",
      "train_loss: 0.16211 valid_loss: 0.17164\n",
      "Validation loss decreased (0.171716 --> 0.171639).  Saving model ...\n",
      "796\n",
      "train_loss: 0.16184 valid_loss: 0.17140\n",
      "Validation loss decreased (0.171639 --> 0.171398).  Saving model ...\n",
      "797\n",
      "train_loss: 0.16212 valid_loss: 0.17149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "798\n",
      "train_loss: 0.16322 valid_loss: 0.17109\n",
      "Validation loss decreased (0.171398 --> 0.171095).  Saving model ...\n",
      "799\n",
      "train_loss: 0.16186 valid_loss: 0.17097\n",
      "Validation loss decreased (0.171095 --> 0.170971).  Saving model ...\n",
      "800\n",
      "train_loss: 0.16189 valid_loss: 0.17109\n",
      "EarlyStopping counter: 1 out of 10\n",
      "801\n",
      "train_loss: 0.16158 valid_loss: 0.17083\n",
      "Validation loss decreased (0.170971 --> 0.170830).  Saving model ...\n",
      "802\n",
      "train_loss: 0.16097 valid_loss: 0.17055\n",
      "Validation loss decreased (0.170830 --> 0.170551).  Saving model ...\n",
      "803\n",
      "train_loss: 0.16142 valid_loss: 0.17065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "804\n",
      "train_loss: 0.16104 valid_loss: 0.17040\n",
      "Validation loss decreased (0.170551 --> 0.170399).  Saving model ...\n",
      "805\n",
      "train_loss: 0.16042 valid_loss: 0.17040\n",
      "Validation loss decreased (0.170399 --> 0.170396).  Saving model ...\n",
      "806\n",
      "train_loss: 0.16019 valid_loss: 0.17020\n",
      "Validation loss decreased (0.170396 --> 0.170202).  Saving model ...\n",
      "807\n",
      "train_loss: 0.16017 valid_loss: 0.17032\n",
      "EarlyStopping counter: 1 out of 10\n",
      "808\n",
      "train_loss: 0.16014 valid_loss: 0.17000\n",
      "Validation loss decreased (0.170202 --> 0.169999).  Saving model ...\n",
      "809\n",
      "train_loss: 0.15984 valid_loss: 0.16992\n",
      "Validation loss decreased (0.169999 --> 0.169916).  Saving model ...\n",
      "810\n",
      "train_loss: 0.15991 valid_loss: 0.16981\n",
      "Validation loss decreased (0.169916 --> 0.169812).  Saving model ...\n",
      "811\n",
      "train_loss: 0.16012 valid_loss: 0.16954\n",
      "Validation loss decreased (0.169812 --> 0.169541).  Saving model ...\n",
      "812\n",
      "train_loss: 0.15930 valid_loss: 0.16948\n",
      "Validation loss decreased (0.169541 --> 0.169483).  Saving model ...\n",
      "813\n",
      "train_loss: 0.15977 valid_loss: 0.16946\n",
      "Validation loss decreased (0.169483 --> 0.169464).  Saving model ...\n",
      "814\n",
      "train_loss: 0.15941 valid_loss: 0.16922\n",
      "Validation loss decreased (0.169464 --> 0.169221).  Saving model ...\n",
      "815\n",
      "train_loss: 0.15897 valid_loss: 0.16899\n",
      "Validation loss decreased (0.169221 --> 0.168986).  Saving model ...\n",
      "816\n",
      "train_loss: 0.15989 valid_loss: 0.16903\n",
      "EarlyStopping counter: 1 out of 10\n",
      "817\n",
      "train_loss: 0.15867 valid_loss: 0.16875\n",
      "Validation loss decreased (0.168986 --> 0.168755).  Saving model ...\n",
      "818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.15868 valid_loss: 0.16879\n",
      "EarlyStopping counter: 1 out of 10\n",
      "819\n",
      "train_loss: 0.15848 valid_loss: 0.16857\n",
      "Validation loss decreased (0.168755 --> 0.168572).  Saving model ...\n",
      "820\n",
      "train_loss: 0.15854 valid_loss: 0.16859\n",
      "EarlyStopping counter: 1 out of 10\n",
      "821\n",
      "train_loss: 0.15887 valid_loss: 0.16840\n",
      "Validation loss decreased (0.168572 --> 0.168400).  Saving model ...\n",
      "822\n",
      "train_loss: 0.15911 valid_loss: 0.16825\n",
      "Validation loss decreased (0.168400 --> 0.168250).  Saving model ...\n",
      "823\n",
      "train_loss: 0.15811 valid_loss: 0.16814\n",
      "Validation loss decreased (0.168250 --> 0.168144).  Saving model ...\n",
      "824\n",
      "train_loss: 0.15763 valid_loss: 0.16816\n",
      "EarlyStopping counter: 1 out of 10\n",
      "825\n",
      "train_loss: 0.15809 valid_loss: 0.16784\n",
      "Validation loss decreased (0.168144 --> 0.167840).  Saving model ...\n",
      "826\n",
      "train_loss: 0.15730 valid_loss: 0.16773\n",
      "Validation loss decreased (0.167840 --> 0.167728).  Saving model ...\n",
      "827\n",
      "train_loss: 0.15843 valid_loss: 0.16784\n",
      "EarlyStopping counter: 1 out of 10\n",
      "828\n",
      "train_loss: 0.15720 valid_loss: 0.16766\n",
      "Validation loss decreased (0.167728 --> 0.167659).  Saving model ...\n",
      "829\n",
      "train_loss: 0.15702 valid_loss: 0.16735\n",
      "Validation loss decreased (0.167659 --> 0.167346).  Saving model ...\n",
      "830\n",
      "train_loss: 0.15684 valid_loss: 0.16737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "831\n",
      "train_loss: 0.15754 valid_loss: 0.16725\n",
      "Validation loss decreased (0.167346 --> 0.167246).  Saving model ...\n",
      "832\n",
      "train_loss: 0.15617 valid_loss: 0.16704\n",
      "Validation loss decreased (0.167246 --> 0.167041).  Saving model ...\n",
      "833\n",
      "train_loss: 0.15717 valid_loss: 0.16699\n",
      "Validation loss decreased (0.167041 --> 0.166986).  Saving model ...\n",
      "834\n",
      "train_loss: 0.15638 valid_loss: 0.16688\n",
      "Validation loss decreased (0.166986 --> 0.166876).  Saving model ...\n",
      "835\n",
      "train_loss: 0.15642 valid_loss: 0.16686\n",
      "Validation loss decreased (0.166876 --> 0.166856).  Saving model ...\n",
      "836\n",
      "train_loss: 0.15655 valid_loss: 0.16666\n",
      "Validation loss decreased (0.166856 --> 0.166660).  Saving model ...\n",
      "837\n",
      "train_loss: 0.15575 valid_loss: 0.16661\n",
      "Validation loss decreased (0.166660 --> 0.166607).  Saving model ...\n",
      "838\n",
      "train_loss: 0.15572 valid_loss: 0.16644\n",
      "Validation loss decreased (0.166607 --> 0.166442).  Saving model ...\n",
      "839\n",
      "train_loss: 0.15579 valid_loss: 0.16623\n",
      "Validation loss decreased (0.166442 --> 0.166230).  Saving model ...\n",
      "840\n",
      "train_loss: 0.15588 valid_loss: 0.16603\n",
      "Validation loss decreased (0.166230 --> 0.166027).  Saving model ...\n",
      "841\n",
      "train_loss: 0.15514 valid_loss: 0.16595\n",
      "Validation loss decreased (0.166027 --> 0.165949).  Saving model ...\n",
      "842\n",
      "train_loss: 0.15507 valid_loss: 0.16591\n",
      "Validation loss decreased (0.165949 --> 0.165907).  Saving model ...\n",
      "843\n",
      "train_loss: 0.15498 valid_loss: 0.16586\n",
      "Validation loss decreased (0.165907 --> 0.165862).  Saving model ...\n",
      "844\n",
      "train_loss: 0.15548 valid_loss: 0.16583\n",
      "Validation loss decreased (0.165862 --> 0.165828).  Saving model ...\n",
      "845\n",
      "train_loss: 0.15500 valid_loss: 0.16564\n",
      "Validation loss decreased (0.165828 --> 0.165644).  Saving model ...\n",
      "846\n",
      "train_loss: 0.15447 valid_loss: 0.16549\n",
      "Validation loss decreased (0.165644 --> 0.165492).  Saving model ...\n",
      "847\n",
      "train_loss: 0.15449 valid_loss: 0.16536\n",
      "Validation loss decreased (0.165492 --> 0.165358).  Saving model ...\n",
      "848\n",
      "train_loss: 0.15435 valid_loss: 0.16531\n",
      "Validation loss decreased (0.165358 --> 0.165309).  Saving model ...\n",
      "849\n",
      "train_loss: 0.15458 valid_loss: 0.16539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "850\n",
      "train_loss: 0.15428 valid_loss: 0.16514\n",
      "Validation loss decreased (0.165309 --> 0.165138).  Saving model ...\n",
      "851\n",
      "train_loss: 0.15391 valid_loss: 0.16487\n",
      "Validation loss decreased (0.165138 --> 0.164868).  Saving model ...\n",
      "852\n",
      "train_loss: 0.15352 valid_loss: 0.16483\n",
      "Validation loss decreased (0.164868 --> 0.164826).  Saving model ...\n",
      "853\n",
      "train_loss: 0.15367 valid_loss: 0.16472\n",
      "Validation loss decreased (0.164826 --> 0.164722).  Saving model ...\n",
      "854\n",
      "train_loss: 0.15368 valid_loss: 0.16459\n",
      "Validation loss decreased (0.164722 --> 0.164588).  Saving model ...\n",
      "855\n",
      "train_loss: 0.15372 valid_loss: 0.16446\n",
      "Validation loss decreased (0.164588 --> 0.164464).  Saving model ...\n",
      "856\n",
      "train_loss: 0.15378 valid_loss: 0.16435\n",
      "Validation loss decreased (0.164464 --> 0.164352).  Saving model ...\n",
      "857\n",
      "train_loss: 0.15378 valid_loss: 0.16428\n",
      "Validation loss decreased (0.164352 --> 0.164275).  Saving model ...\n",
      "858\n",
      "train_loss: 0.15285 valid_loss: 0.16406\n",
      "Validation loss decreased (0.164275 --> 0.164062).  Saving model ...\n",
      "859\n",
      "train_loss: 0.15333 valid_loss: 0.16398\n",
      "Validation loss decreased (0.164062 --> 0.163985).  Saving model ...\n",
      "860\n",
      "train_loss: 0.15272 valid_loss: 0.16396\n",
      "Validation loss decreased (0.163985 --> 0.163957).  Saving model ...\n",
      "861\n",
      "train_loss: 0.15433 valid_loss: 0.16378\n",
      "Validation loss decreased (0.163957 --> 0.163780).  Saving model ...\n",
      "862\n",
      "train_loss: 0.15237 valid_loss: 0.16377\n",
      "Validation loss decreased (0.163780 --> 0.163767).  Saving model ...\n",
      "863\n",
      "train_loss: 0.15324 valid_loss: 0.16363\n",
      "Validation loss decreased (0.163767 --> 0.163635).  Saving model ...\n",
      "864\n",
      "train_loss: 0.15237 valid_loss: 0.16341\n",
      "Validation loss decreased (0.163635 --> 0.163407).  Saving model ...\n",
      "865\n",
      "train_loss: 0.15250 valid_loss: 0.16342\n",
      "EarlyStopping counter: 1 out of 10\n",
      "866\n",
      "train_loss: 0.15223 valid_loss: 0.16344\n",
      "EarlyStopping counter: 2 out of 10\n",
      "867\n",
      "train_loss: 0.15168 valid_loss: 0.16328\n",
      "Validation loss decreased (0.163407 --> 0.163282).  Saving model ...\n",
      "868\n",
      "train_loss: 0.15196 valid_loss: 0.16292\n",
      "Validation loss decreased (0.163282 --> 0.162919).  Saving model ...\n",
      "869\n",
      "train_loss: 0.15174 valid_loss: 0.16302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "870\n",
      "train_loss: 0.15194 valid_loss: 0.16293\n",
      "EarlyStopping counter: 2 out of 10\n",
      "871\n",
      "train_loss: 0.15099 valid_loss: 0.16274\n",
      "Validation loss decreased (0.162919 --> 0.162742).  Saving model ...\n",
      "872\n",
      "train_loss: 0.15177 valid_loss: 0.16265\n",
      "Validation loss decreased (0.162742 --> 0.162651).  Saving model ...\n",
      "873\n",
      "train_loss: 0.15072 valid_loss: 0.16262\n",
      "Validation loss decreased (0.162651 --> 0.162618).  Saving model ...\n",
      "874\n",
      "train_loss: 0.15088 valid_loss: 0.16251\n",
      "Validation loss decreased (0.162618 --> 0.162512).  Saving model ...\n",
      "875\n",
      "train_loss: 0.15113 valid_loss: 0.16253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "876\n",
      "train_loss: 0.15085 valid_loss: 0.16224\n",
      "Validation loss decreased (0.162512 --> 0.162243).  Saving model ...\n",
      "877\n",
      "train_loss: 0.15148 valid_loss: 0.16226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "878\n",
      "train_loss: 0.15074 valid_loss: 0.16204\n",
      "Validation loss decreased (0.162243 --> 0.162037).  Saving model ...\n",
      "879\n",
      "train_loss: 0.15078 valid_loss: 0.16194\n",
      "Validation loss decreased (0.162037 --> 0.161937).  Saving model ...\n",
      "880\n",
      "train_loss: 0.15014 valid_loss: 0.16183\n",
      "Validation loss decreased (0.161937 --> 0.161828).  Saving model ...\n",
      "881\n",
      "train_loss: 0.14972 valid_loss: 0.16191\n",
      "EarlyStopping counter: 1 out of 10\n",
      "882\n",
      "train_loss: 0.15109 valid_loss: 0.16156\n",
      "Validation loss decreased (0.161828 --> 0.161559).  Saving model ...\n",
      "883\n",
      "train_loss: 0.15010 valid_loss: 0.16147\n",
      "Validation loss decreased (0.161559 --> 0.161475).  Saving model ...\n",
      "884\n",
      "train_loss: 0.15073 valid_loss: 0.16143\n",
      "Validation loss decreased (0.161475 --> 0.161426).  Saving model ...\n",
      "885\n",
      "train_loss: 0.14944 valid_loss: 0.16140\n",
      "Validation loss decreased (0.161426 --> 0.161399).  Saving model ...\n",
      "886\n",
      "train_loss: 0.15054 valid_loss: 0.16125\n",
      "Validation loss decreased (0.161399 --> 0.161245).  Saving model ...\n",
      "887\n",
      "train_loss: 0.14976 valid_loss: 0.16104\n",
      "Validation loss decreased (0.161245 --> 0.161040).  Saving model ...\n",
      "888\n",
      "train_loss: 0.14925 valid_loss: 0.16099\n",
      "Validation loss decreased (0.161040 --> 0.160992).  Saving model ...\n",
      "889\n",
      "train_loss: 0.14954 valid_loss: 0.16096\n",
      "Validation loss decreased (0.160992 --> 0.160961).  Saving model ...\n",
      "890\n",
      "train_loss: 0.14908 valid_loss: 0.16084\n",
      "Validation loss decreased (0.160961 --> 0.160837).  Saving model ...\n",
      "891\n",
      "train_loss: 0.14920 valid_loss: 0.16068\n",
      "Validation loss decreased (0.160837 --> 0.160682).  Saving model ...\n",
      "892\n",
      "train_loss: 0.14985 valid_loss: 0.16057\n",
      "Validation loss decreased (0.160682 --> 0.160566).  Saving model ...\n",
      "893\n",
      "train_loss: 0.14867 valid_loss: 0.16064\n",
      "EarlyStopping counter: 1 out of 10\n",
      "894\n",
      "train_loss: 0.14861 valid_loss: 0.16033\n",
      "Validation loss decreased (0.160566 --> 0.160326).  Saving model ...\n",
      "895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.14826 valid_loss: 0.16025\n",
      "Validation loss decreased (0.160326 --> 0.160250).  Saving model ...\n",
      "896\n",
      "train_loss: 0.14904 valid_loss: 0.16023\n",
      "Validation loss decreased (0.160250 --> 0.160230).  Saving model ...\n",
      "897\n",
      "train_loss: 0.14840 valid_loss: 0.16009\n",
      "Validation loss decreased (0.160230 --> 0.160091).  Saving model ...\n",
      "898\n",
      "train_loss: 0.14791 valid_loss: 0.15988\n",
      "Validation loss decreased (0.160091 --> 0.159885).  Saving model ...\n",
      "899\n",
      "train_loss: 0.14875 valid_loss: 0.15999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "900\n",
      "train_loss: 0.14865 valid_loss: 0.15969\n",
      "Validation loss decreased (0.159885 --> 0.159687).  Saving model ...\n",
      "901\n",
      "train_loss: 0.14828 valid_loss: 0.15974\n",
      "EarlyStopping counter: 1 out of 10\n",
      "902\n",
      "train_loss: 0.14748 valid_loss: 0.15975\n",
      "EarlyStopping counter: 2 out of 10\n",
      "903\n",
      "train_loss: 0.14744 valid_loss: 0.15948\n",
      "Validation loss decreased (0.159687 --> 0.159481).  Saving model ...\n",
      "904\n",
      "train_loss: 0.14805 valid_loss: 0.15940\n",
      "Validation loss decreased (0.159481 --> 0.159399).  Saving model ...\n",
      "905\n",
      "train_loss: 0.14808 valid_loss: 0.15920\n",
      "Validation loss decreased (0.159399 --> 0.159200).  Saving model ...\n",
      "906\n",
      "train_loss: 0.14808 valid_loss: 0.15928\n",
      "EarlyStopping counter: 1 out of 10\n",
      "907\n",
      "train_loss: 0.14717 valid_loss: 0.15911\n",
      "Validation loss decreased (0.159200 --> 0.159107).  Saving model ...\n",
      "908\n",
      "train_loss: 0.14694 valid_loss: 0.15896\n",
      "Validation loss decreased (0.159107 --> 0.158962).  Saving model ...\n",
      "909\n",
      "train_loss: 0.14636 valid_loss: 0.15887\n",
      "Validation loss decreased (0.158962 --> 0.158872).  Saving model ...\n",
      "910\n",
      "train_loss: 0.14712 valid_loss: 0.15870\n",
      "Validation loss decreased (0.158872 --> 0.158696).  Saving model ...\n",
      "911\n",
      "train_loss: 0.14647 valid_loss: 0.15863\n",
      "Validation loss decreased (0.158696 --> 0.158626).  Saving model ...\n",
      "912\n",
      "train_loss: 0.14697 valid_loss: 0.15872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "913\n",
      "train_loss: 0.14688 valid_loss: 0.15849\n",
      "Validation loss decreased (0.158626 --> 0.158486).  Saving model ...\n",
      "914\n",
      "train_loss: 0.14625 valid_loss: 0.15834\n",
      "Validation loss decreased (0.158486 --> 0.158335).  Saving model ...\n",
      "915\n",
      "train_loss: 0.14583 valid_loss: 0.15825\n",
      "Validation loss decreased (0.158335 --> 0.158255).  Saving model ...\n",
      "916\n",
      "train_loss: 0.14625 valid_loss: 0.15818\n",
      "Validation loss decreased (0.158255 --> 0.158180).  Saving model ...\n",
      "917\n",
      "train_loss: 0.14597 valid_loss: 0.15802\n",
      "Validation loss decreased (0.158180 --> 0.158018).  Saving model ...\n",
      "918\n",
      "train_loss: 0.14618 valid_loss: 0.15795\n",
      "Validation loss decreased (0.158018 --> 0.157950).  Saving model ...\n",
      "919\n",
      "train_loss: 0.14557 valid_loss: 0.15795\n",
      "EarlyStopping counter: 1 out of 10\n",
      "920\n",
      "train_loss: 0.14623 valid_loss: 0.15777\n",
      "Validation loss decreased (0.157950 --> 0.157767).  Saving model ...\n",
      "921\n",
      "train_loss: 0.14524 valid_loss: 0.15767\n",
      "Validation loss decreased (0.157767 --> 0.157668).  Saving model ...\n",
      "922\n",
      "train_loss: 0.14468 valid_loss: 0.15763\n",
      "Validation loss decreased (0.157668 --> 0.157632).  Saving model ...\n",
      "923\n",
      "train_loss: 0.14580 valid_loss: 0.15743\n",
      "Validation loss decreased (0.157632 --> 0.157427).  Saving model ...\n",
      "924\n",
      "train_loss: 0.14467 valid_loss: 0.15736\n",
      "Validation loss decreased (0.157427 --> 0.157363).  Saving model ...\n",
      "925\n",
      "train_loss: 0.14528 valid_loss: 0.15725\n",
      "Validation loss decreased (0.157363 --> 0.157250).  Saving model ...\n",
      "926\n",
      "train_loss: 0.14548 valid_loss: 0.15712\n",
      "Validation loss decreased (0.157250 --> 0.157120).  Saving model ...\n",
      "927\n",
      "train_loss: 0.14514 valid_loss: 0.15719\n",
      "EarlyStopping counter: 1 out of 10\n",
      "928\n",
      "train_loss: 0.14417 valid_loss: 0.15693\n",
      "Validation loss decreased (0.157120 --> 0.156930).  Saving model ...\n",
      "929\n",
      "train_loss: 0.14398 valid_loss: 0.15679\n",
      "Validation loss decreased (0.156930 --> 0.156790).  Saving model ...\n",
      "930\n",
      "train_loss: 0.14404 valid_loss: 0.15682\n",
      "EarlyStopping counter: 1 out of 10\n",
      "931\n",
      "train_loss: 0.14422 valid_loss: 0.15672\n",
      "Validation loss decreased (0.156790 --> 0.156722).  Saving model ...\n",
      "932\n",
      "train_loss: 0.14404 valid_loss: 0.15652\n",
      "Validation loss decreased (0.156722 --> 0.156522).  Saving model ...\n",
      "933\n",
      "train_loss: 0.14437 valid_loss: 0.15650\n",
      "Validation loss decreased (0.156522 --> 0.156504).  Saving model ...\n",
      "934\n",
      "train_loss: 0.14369 valid_loss: 0.15656\n",
      "EarlyStopping counter: 1 out of 10\n",
      "935\n",
      "train_loss: 0.14369 valid_loss: 0.15622\n",
      "Validation loss decreased (0.156504 --> 0.156219).  Saving model ...\n",
      "936\n",
      "train_loss: 0.14407 valid_loss: 0.15621\n",
      "Validation loss decreased (0.156219 --> 0.156207).  Saving model ...\n",
      "937\n",
      "train_loss: 0.14282 valid_loss: 0.15603\n",
      "Validation loss decreased (0.156207 --> 0.156027).  Saving model ...\n",
      "938\n",
      "train_loss: 0.14317 valid_loss: 0.15610\n",
      "EarlyStopping counter: 1 out of 10\n",
      "939\n",
      "train_loss: 0.14296 valid_loss: 0.15602\n",
      "Validation loss decreased (0.156027 --> 0.156022).  Saving model ...\n",
      "940\n",
      "train_loss: 0.14307 valid_loss: 0.15591\n",
      "Validation loss decreased (0.156022 --> 0.155908).  Saving model ...\n",
      "941\n",
      "train_loss: 0.14278 valid_loss: 0.15562\n",
      "Validation loss decreased (0.155908 --> 0.155619).  Saving model ...\n",
      "942\n",
      "train_loss: 0.14325 valid_loss: 0.15567\n",
      "EarlyStopping counter: 1 out of 10\n",
      "943\n",
      "train_loss: 0.14283 valid_loss: 0.15575\n",
      "EarlyStopping counter: 2 out of 10\n",
      "944\n",
      "train_loss: 0.14221 valid_loss: 0.15544\n",
      "Validation loss decreased (0.155619 --> 0.155443).  Saving model ...\n",
      "945\n",
      "train_loss: 0.14189 valid_loss: 0.15525\n",
      "Validation loss decreased (0.155443 --> 0.155253).  Saving model ...\n",
      "946\n",
      "train_loss: 0.14258 valid_loss: 0.15530\n",
      "EarlyStopping counter: 1 out of 10\n",
      "947\n",
      "train_loss: 0.14258 valid_loss: 0.15544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "948\n",
      "train_loss: 0.14179 valid_loss: 0.15518\n",
      "Validation loss decreased (0.155253 --> 0.155177).  Saving model ...\n",
      "949\n",
      "train_loss: 0.14207 valid_loss: 0.15496\n",
      "Validation loss decreased (0.155177 --> 0.154958).  Saving model ...\n",
      "950\n",
      "train_loss: 0.14190 valid_loss: 0.15504\n",
      "EarlyStopping counter: 1 out of 10\n",
      "951\n",
      "train_loss: 0.14252 valid_loss: 0.15484\n",
      "Validation loss decreased (0.154958 --> 0.154845).  Saving model ...\n",
      "952\n",
      "train_loss: 0.14242 valid_loss: 0.15485\n",
      "EarlyStopping counter: 1 out of 10\n",
      "953\n",
      "train_loss: 0.14174 valid_loss: 0.15474\n",
      "Validation loss decreased (0.154845 --> 0.154738).  Saving model ...\n",
      "954\n",
      "train_loss: 0.14127 valid_loss: 0.15459\n",
      "Validation loss decreased (0.154738 --> 0.154595).  Saving model ...\n",
      "955\n",
      "train_loss: 0.14233 valid_loss: 0.15443\n",
      "Validation loss decreased (0.154595 --> 0.154426).  Saving model ...\n",
      "956\n",
      "train_loss: 0.14157 valid_loss: 0.15433\n",
      "Validation loss decreased (0.154426 --> 0.154329).  Saving model ...\n",
      "957\n",
      "train_loss: 0.14104 valid_loss: 0.15431\n",
      "Validation loss decreased (0.154329 --> 0.154307).  Saving model ...\n",
      "958\n",
      "train_loss: 0.14078 valid_loss: 0.15437\n",
      "EarlyStopping counter: 1 out of 10\n",
      "959\n",
      "train_loss: 0.14095 valid_loss: 0.15424\n",
      "Validation loss decreased (0.154307 --> 0.154243).  Saving model ...\n",
      "960\n",
      "train_loss: 0.14084 valid_loss: 0.15415\n",
      "Validation loss decreased (0.154243 --> 0.154149).  Saving model ...\n",
      "961\n",
      "train_loss: 0.14069 valid_loss: 0.15397\n",
      "Validation loss decreased (0.154149 --> 0.153975).  Saving model ...\n",
      "962\n",
      "train_loss: 0.14033 valid_loss: 0.15383\n",
      "Validation loss decreased (0.153975 --> 0.153833).  Saving model ...\n",
      "963\n",
      "train_loss: 0.14065 valid_loss: 0.15396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "964\n",
      "train_loss: 0.14022 valid_loss: 0.15357\n",
      "Validation loss decreased (0.153833 --> 0.153566).  Saving model ...\n",
      "965\n",
      "train_loss: 0.14042 valid_loss: 0.15352\n",
      "Validation loss decreased (0.153566 --> 0.153524).  Saving model ...\n",
      "966\n",
      "train_loss: 0.14006 valid_loss: 0.15344\n",
      "Validation loss decreased (0.153524 --> 0.153437).  Saving model ...\n",
      "967\n",
      "train_loss: 0.13956 valid_loss: 0.15356\n",
      "EarlyStopping counter: 1 out of 10\n",
      "968\n",
      "train_loss: 0.13961 valid_loss: 0.15337\n",
      "Validation loss decreased (0.153437 --> 0.153372).  Saving model ...\n",
      "969\n",
      "train_loss: 0.13958 valid_loss: 0.15329\n",
      "Validation loss decreased (0.153372 --> 0.153288).  Saving model ...\n",
      "970\n",
      "train_loss: 0.13954 valid_loss: 0.15311\n",
      "Validation loss decreased (0.153288 --> 0.153109).  Saving model ...\n",
      "971\n",
      "train_loss: 0.13944 valid_loss: 0.15319\n",
      "EarlyStopping counter: 1 out of 10\n",
      "972\n",
      "train_loss: 0.13935 valid_loss: 0.15293\n",
      "Validation loss decreased (0.153109 --> 0.152930).  Saving model ...\n",
      "973\n",
      "train_loss: 0.13928 valid_loss: 0.15281\n",
      "Validation loss decreased (0.152930 --> 0.152812).  Saving model ...\n",
      "974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.13912 valid_loss: 0.15291\n",
      "EarlyStopping counter: 1 out of 10\n",
      "975\n",
      "train_loss: 0.13937 valid_loss: 0.15269\n",
      "Validation loss decreased (0.152812 --> 0.152688).  Saving model ...\n",
      "976\n",
      "train_loss: 0.13854 valid_loss: 0.15260\n",
      "Validation loss decreased (0.152688 --> 0.152602).  Saving model ...\n",
      "977\n",
      "train_loss: 0.14001 valid_loss: 0.15230\n",
      "Validation loss decreased (0.152602 --> 0.152302).  Saving model ...\n",
      "978\n",
      "train_loss: 0.13849 valid_loss: 0.15234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "979\n",
      "train_loss: 0.13788 valid_loss: 0.15221\n",
      "Validation loss decreased (0.152302 --> 0.152212).  Saving model ...\n",
      "980\n",
      "train_loss: 0.13818 valid_loss: 0.15213\n",
      "Validation loss decreased (0.152212 --> 0.152133).  Saving model ...\n",
      "981\n",
      "train_loss: 0.13824 valid_loss: 0.15217\n",
      "EarlyStopping counter: 1 out of 10\n",
      "982\n",
      "train_loss: 0.13835 valid_loss: 0.15206\n",
      "Validation loss decreased (0.152133 --> 0.152061).  Saving model ...\n",
      "983\n",
      "train_loss: 0.13776 valid_loss: 0.15188\n",
      "Validation loss decreased (0.152061 --> 0.151881).  Saving model ...\n",
      "984\n",
      "train_loss: 0.13878 valid_loss: 0.15187\n",
      "Validation loss decreased (0.151881 --> 0.151873).  Saving model ...\n",
      "985\n",
      "train_loss: 0.13765 valid_loss: 0.15172\n",
      "Validation loss decreased (0.151873 --> 0.151716).  Saving model ...\n",
      "986\n",
      "train_loss: 0.13759 valid_loss: 0.15161\n",
      "Validation loss decreased (0.151716 --> 0.151611).  Saving model ...\n",
      "987\n",
      "train_loss: 0.13774 valid_loss: 0.15161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "988\n",
      "train_loss: 0.13820 valid_loss: 0.15141\n",
      "Validation loss decreased (0.151611 --> 0.151405).  Saving model ...\n",
      "989\n",
      "train_loss: 0.13781 valid_loss: 0.15129\n",
      "Validation loss decreased (0.151405 --> 0.151294).  Saving model ...\n",
      "990\n",
      "train_loss: 0.13710 valid_loss: 0.15143\n",
      "EarlyStopping counter: 1 out of 10\n",
      "991\n",
      "train_loss: 0.13710 valid_loss: 0.15127\n",
      "Validation loss decreased (0.151294 --> 0.151272).  Saving model ...\n",
      "992\n",
      "train_loss: 0.13744 valid_loss: 0.15108\n",
      "Validation loss decreased (0.151272 --> 0.151080).  Saving model ...\n",
      "993\n",
      "train_loss: 0.13732 valid_loss: 0.15108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "994\n",
      "train_loss: 0.13686 valid_loss: 0.15128\n",
      "EarlyStopping counter: 2 out of 10\n",
      "995\n",
      "train_loss: 0.13728 valid_loss: 0.15092\n",
      "Validation loss decreased (0.151080 --> 0.150916).  Saving model ...\n",
      "996\n",
      "train_loss: 0.13746 valid_loss: 0.15081\n",
      "Validation loss decreased (0.150916 --> 0.150812).  Saving model ...\n",
      "997\n",
      "train_loss: 0.13701 valid_loss: 0.15088\n",
      "EarlyStopping counter: 1 out of 10\n",
      "998\n",
      "train_loss: 0.13702 valid_loss: 0.15063\n",
      "Validation loss decreased (0.150812 --> 0.150633).  Saving model ...\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "size = len(train_loader.dataset)\n",
    "print(size)\n",
    "\n",
    "# initialize the early_stopping object\n",
    "early_stopping = pytorchtools.EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ##########################    \n",
    "    #######TRAIN MODEL########\n",
    "    ##########################\n",
    "    epochs_loss=0\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "#         images = images.view(images.shape[0], -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "#         print(images.shape)\n",
    "        # Forward pass\n",
    "        outputs = model(images).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backprpagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #calculate train_loss\n",
    "        train_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    ##########################    \n",
    "    #####VALIDATE MODEL#######\n",
    "    ##########################\n",
    "    model.eval()\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images).to(device)\n",
    "        loss = criterion(outputs,labels)\n",
    "        valid_losses.append(loss.item())\n",
    "    \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = numpy.average(train_losses)\n",
    "    valid_loss = numpy.average(valid_losses)\n",
    "#     print(train_loss)\n",
    "    avg_train_losses.append(train_loss)\n",
    "    avg_valid_losses.append(valid_loss)\n",
    "    \n",
    "    print_msg = (f'train_loss: {train_loss:.5f} ' + f'valid_loss: {valid_loss:.5f}')\n",
    "    \n",
    "    print(print_msg)\n",
    "\n",
    "    \n",
    "    # clear lists to track next epoch\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    early_stopping(valid_loss, model)\n",
    "    print(epoch)\n",
    "        \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the last checkpoint with the best model\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "######1st plot#########\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.set_ylabel('valid  /  train loss')\n",
    "ax1.set_xlabel('number of epochs')\n",
    "halt = avg_valid_losses.index(min(avg_valid_losses))\n",
    "\n",
    "\n",
    "plt.axvline(x=halt, color='r', linestyle=\"--\", label=\"stop training\")\n",
    "\n",
    "print(avg_valid_losses.index(min(avg_valid_losses)))\n",
    "\n",
    "\n",
    "plt.plot(list(range(len(avg_valid_losses))), avg_valid_losses, label = \"valid loss\")\n",
    "plt.plot(list(range(len(avg_valid_losses))), avg_train_losses, label=\"train loss\")\n",
    "\n",
    "h,labels = ax1.get_legend_handles_labels()\n",
    "labels[:1] = ['stop training','valid loss', 'train loss',]\n",
    "ax1.legend(labels=labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.57 %\n"
     ]
    }
   ],
   "source": [
    "# In the test phase, don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'models\\\\net_custom2.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([]).to(device)\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        images = images.reshape(-1,28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(images).to(device)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total correct 9557\n",
      "accuracy 0.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_loader = torch.utils.data.DataLoader(test_dataset, batch_size =10000)\n",
    "    train_preds = get_all_preds(model, prediction_loader).to(device)\n",
    "    \n",
    "train_preds.shape\n",
    "train_preds.grad_fn\n",
    "train_preds.grad\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "preds_correct = get_num_correct(train_preds, test_dataset.targets.to(device) )\n",
    "print('total correct', preds_correct)\n",
    "print('accuracy', preds_correct / len(test_dataset))\n",
    "train_preds.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.stack((test_dataset.targets.to(device), train_preds.argmax(dim=1)), dim=1)\n",
    "stacked[9].tolist()\n",
    "cmt = torch.zeros(10,10, dtype=torch.int64)\n",
    "for p in stacked:\n",
    "    j,k = p.tolist()\n",
    "    cmt[j,k] = cmt[j, k] + 1\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = test_dataset.targets.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "rp = train_preds.argmax(dim=1).detach().cpu().numpy()\n",
    "print(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(lb, rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 960    0    1    1    0    6    5    3    3    1]\n",
      " [   0 1117    2    2    0    1    5    2    6    0]\n",
      " [   6    4  981    5    6    1    8    9   11    1]\n",
      " [   2    1    8  963    0   14    1   11    7    3]\n",
      " [   1    1    6    0  937    0   11    2    3   21]\n",
      " [   9    1    1   15    5  839    8    0    7    7]\n",
      " [   7    3    2    0    6    9  925    1    5    0]\n",
      " [   1    6   20    3    1    1    0  979    1   16]\n",
      " [   7    5    4   12    9    7    8    7  912    3]\n",
      " [   9    6    1   10   20    4    1    9    5  944]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = set(lb)\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            target = target.to(device)\n",
    "            data = data.reshape(-1,28*28).to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            # Store wrongly predicted images\n",
    "            wrong_idx = (pred != target.view_as(pred)).nonzero()[:, 0]\n",
    "            wrong_samples = data[wrong_idx]\n",
    "            wrong_preds = pred[wrong_idx]\n",
    "            actual_preds = target.view_as(pred)[wrong_idx]\n",
    "\n",
    "            for i in range(len(wrong_idx)):\n",
    "                sample = wrong_samples[i]\n",
    "                wrong_pred = wrong_preds[i]\n",
    "                actual_pred = actual_preds[i]\n",
    "                # Undo normalization\n",
    "#                 print(wrong_samples[i].shape)\n",
    "                sample = sample.reshape(28,28).to(device)\n",
    "                sample = sample * 0.3081\n",
    "                sample = sample + 0.1307\n",
    "                sample = sample * 255.\n",
    "                sample = sample.byte()\n",
    "                img = TF.to_pil_image(sample)\n",
    "                path = '.\\\\mistakes\\\\net_custom2\\\\'\n",
    "                img.save(path+'wrong_idx{}_pred{}_actual{}.png'.format(\n",
    "                    wrong_idx[i], wrong_pred.item(), actual_pred.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model,device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
